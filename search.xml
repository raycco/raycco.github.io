<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Android Audio HAL server启动]]></title>
    <url>%2F2017%2F11%2F28%2FAndroid-Audio-HAL-server%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[我们知道硬件抽象层（HAL）是连接driver和native的桥梁，数据会从native层到HAL层，最终写入kernel。然而8.0之前的HAL和native处于同一进程，耦合度比较高。所以在Android 8.0，google对HAL做了重构，将HAL放在独立的进程，和native通过binder通信。下面我们就看看Android Audio HAL server的启动。 Audio HAL server启动同样Android Audio HAL server（audio-hal-2-0）从init进程启动，不过audio-hal-2-0的可执行文件在vendor分区，这也是为了降低耦合度，因为HAL一般由OEM/ODM实现，google不想HAL影响到Framework的更新，所以希望尽量将OEM/ODM的实现放到vendor分区，由这些厂商自己维护。12345678910111213service audio-hal-2-0 /vendor/bin/hw/android.hardware.audio@2.0-service class hal # audio-hal-2-0和class hal行为一致 user audioserver # 用户归属，uid：AID_AUDIOSERVER # media gid needed for /dev/fm (radio) and for /data/misc/media (tee) group audio camera drmrpc inet media mediadrm net_bt \ net_bt_admin net_bw_acct # 用户组归属 ioprio rt 4 # io调度优先级 # 当子进程被创建的时候，将子进程的pid写入到给定的文件中,cgroup/cpuset用法 writepid /dev/cpuset/foreground/tasks /dev/stune/foreground/tasks # audioflinger restarts itself when it loses connection with the hal # and its .rc file has an "onrestart restart audio-hal" rule, thus # an additional auto-restart from the init process isn't needed. oneshot # 当此服务退出时不会自动重启 我们看到audio-hal-2-0的启动代码有IDevicesFactory，IEffectsFactory，ISoundTriggerHw及IBroadcastRadioFactory，这和native的audioserver相对应。且代码有一种熟悉的感觉，和audioserver的启动很相似，只是具体实现有些不一样，这里通过registerPassthroughServiceImplementation将如上四个服务注册到hwservicemanager，以供native调用。12345678910111213141516171819202122int main(int /* argc */, char* /* argv */ []) &#123; configureRpcThreadpool(16, true /*callerWillJoin*/); android::status_t status; status = registerPassthroughServiceImplementation&lt;IDevicesFactory&gt;(); LOG_ALWAYS_FATAL_IF(status != OK, "Error while registering audio service: %d", status); status = registerPassthroughServiceImplementation&lt;IEffectsFactory&gt;(); LOG_ALWAYS_FATAL_IF(status != OK, "Error while registering audio effects service: %d", status); // Soundtrigger and FM radio might be not present. status = registerPassthroughServiceImplementation&lt;ISoundTriggerHw&gt;(); ALOGE_IF(status != OK, "Error while registering soundtrigger service: %d", status); if (useBroadcastRadioFutureFeatures) &#123; status = registerPassthroughServiceImplementation&lt; broadcastradio::V1_1::IBroadcastRadioFactory&gt;(); &#125; else &#123; status = registerPassthroughServiceImplementation&lt; broadcastradio::V1_0::IBroadcastRadioFactory&gt;(); &#125; ALOGE_IF(status != OK, "Error while registering fm radio service: %d", status); joinRpcThreadpool(); return status;&#125; IDevicesFactory注册到hwservicemanager在如上的启动代码中我们看到，HAL服务端调用registerPassthroughServiceImplementation实现注册，这函数的实现在system/libhidl/transport/include/hidl/LegacySupport.h,这是一个模板方法，这里传入IDevicesFactory接口。1234567891011121314151617/** * Registers passthrough service implementation. */template&lt;class Interface&gt;__attribute__((warn_unused_result))status_t registerPassthroughServiceImplementation( std::string name = "default") &#123; sp&lt;Interface&gt; service = Interface::getService(name, true /* getStub */); ...... status_t status = service-&gt;registerAsService(name); ...... return status;&#125; 所以首先会调用IDevicesFactory的getService方法。在IDevicesFactory.h中看到有getService方法的声明，在DevicesFactoryAll.cpp中有此方法的实现，最后会返回BsDevicesFactory实例。12345678910111213141516171819202122232425262728293031const char* IDevicesFactory::descriptor("android.hardware.audio@2.0::IDevicesFactory");::android::sp&lt;IDevicesFactory&gt; IDevicesFactory::getService( const std::string &amp;serviceName, const bool getStub) &#123; using ::android::hardware::defaultServiceManager; using ::android::hardware::details::waitForHwService; using ::android::hardware::getPassthroughServiceManager; using ::android::hardware::Return; using ::android::sp; using Transport = ::android::hidl::manager::V1_0::IServiceManager::Transport; sp&lt;IDevicesFactory&gt; iface = nullptr; ...... if (getStub || vintfPassthru || vintfLegacy) &#123; const sp&lt;::android::hidl::manager::V1_0::IServiceManager&gt; pm = getPassthroughServiceManager(); if (pm != nullptr) &#123; Return&lt;sp&lt;::android::hidl::base::V1_0::IBase&gt;&gt; ret = pm-&gt;get(IDevicesFactory::descriptor, serviceName); if (ret.isOk()) &#123; sp&lt;::android::hidl::base::V1_0::IBase&gt; baseInterface = ret; if (baseInterface != nullptr) &#123; iface = new BsDevicesFactory(IDevicesFactory::castFrom(baseInterface)); &#125; &#125; &#125; &#125; return iface;&#125; 这里getStub为true，所以前面一段代码不会执行，直接创建PassthroughServiceManager，PassthroughServiceManager的实现在system/libhidl/transport/ServiceManagement.cpp，然后执行其get方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283Return&lt;sp&lt;IBase&gt;&gt; get(const hidl_string&amp; fqName, const hidl_string&amp; name) override &#123; std::string stdFqName(fqName.c_str()); //fqName looks like android.hardware.foo@1.0::IFoo size_t idx = stdFqName.find("::"); if (idx == std::string::npos || idx + strlen("::") + 1 &gt;= stdFqName.size()) &#123; LOG(ERROR) &lt;&lt; "Invalid interface name passthrough lookup: " &lt;&lt; fqName; return nullptr; &#125; // packageAndVersion为android.hardware.audio@2.0 std::string packageAndVersion = stdFqName.substr(0, idx); // ifaceName为IDevicesFactory std::string ifaceName = stdFqName.substr(idx + strlen("::")); const std::string prefix = packageAndVersion + "-impl"; const std::string sym = "HIDL_FETCH_" + ifaceName; const android_namespace_t* sphal_namespace = android_get_exported_namespace("sphal"); const int dlMode = RTLD_LAZY; void *handle = nullptr; // TODO: lookup in VINTF instead // TODO(b/34135607): Remove HAL_LIBRARY_PATH_SYSTEM dlerror(); // clear // 在/odm/lib(64)/hw/，/vendor/lib(64)/hw/，/system/lib(64)/hw/ // 寻找android.hardware.audio@2.0-impl.so并用dlopen打开，执行 // HIDL_FETCH_IDevicesFactory函数,创建DevicesFactory实例 for (const std::string &amp;path : &#123; HAL_LIBRARY_PATH_ODM, HAL_LIBRARY_PATH_VENDOR, HAL_LIBRARY_PATH_SYSTEM &#125;) &#123; std::vector&lt;std::string&gt; libs = search(path, prefix, ".so"); for (const std::string &amp;lib : libs) &#123; const std::string fullPath = path + lib; // If sphal namespace is available, try to load from the // namespace first. If it fails, fall back to the original // dlopen, which loads from the current namespace. if (sphal_namespace != nullptr &amp;&amp; path != HAL_LIBRARY_PATH_SYSTEM) &#123; const android_dlextinfo dlextinfo = &#123; .flags = ANDROID_DLEXT_USE_NAMESPACE, // const_cast is dirty but required because // library_namespace field is non-const. .library_namespace = const_cast&lt;android_namespace_t*&gt;(sphal_namespace), &#125;; handle = android_dlopen_ext(fullPath.c_str(), dlMode, &amp;dlextinfo); if (handle == nullptr) &#123; const char* error = dlerror(); LOG(WARNING) &lt;&lt; "Failed to dlopen " &lt;&lt; lib &lt;&lt; " from sphal namespace:" &lt;&lt; (error == nullptr ? "unknown error" : error); &#125; else &#123; LOG(DEBUG) &lt;&lt; lib &lt;&lt; " loaded from sphal namespace."; &#125; &#125; if (handle == nullptr) &#123; handle = dlopen(fullPath.c_str(), dlMode); &#125; if (handle == nullptr) &#123; const char* error = dlerror(); LOG(ERROR) &lt;&lt; "Failed to dlopen " &lt;&lt; lib &lt;&lt; ": " &lt;&lt; (error == nullptr ? "unknown error" : error); continue; &#125; IBase* (*generator)(const char* name); *(void **)(&amp;generator) = dlsym(handle, sym.c_str()); if(!generator) &#123; const char* error = dlerror(); LOG(ERROR) &lt;&lt; "Passthrough lookup opened " &lt;&lt; lib &lt;&lt; " but could not find symbol " &lt;&lt; sym &lt;&lt; ": " &lt;&lt; (error == nullptr ? "unknown error" : error); dlclose(handle); continue; &#125; IBase *interface = (*generator)(name.c_str()); if (interface == nullptr) &#123; dlclose(handle); continue; // this module doesn't provide this instance name &#125; registerReference(fqName, name); return interface; &#125; &#125; return nullptr;&#125; 根据android.hardware.audio@2.0::IDevicesFactory字串拼接出android.hardware.audio@2.0-impl.so并找到打开，执行HIDL_FETCH_IDevicesFactory函数创建DevicesFactory返回。得到BsDevicesFactory实例后，会执行其registerAsService。123456789101112::android::status_t IDevicesFactory::registerAsService(const std::string &amp;serviceName) &#123; ::android::hardware::details::onRegistration( "android.hardware.audio@2.0", "IDevicesFactory", serviceName); const ::android::sp&lt;::android::hidl::manager::V1_0::IServiceManager&gt; sm = ::android::hardware::defaultServiceManager(); if (sm == nullptr) &#123; return ::android::INVALID_OPERATION; &#125; ::android::hardware::Return&lt;bool&gt; ret = sm-&gt;add(serviceName.c_str(), this); return ret.isOk() &amp;&amp; ret ? ::android::OK : ::android::UNKNOWN_ERROR;&#125; 获取HwServiceManager将自己注册到hwservicemanager。这里涉及binder通信机制，关于binder通信，是另外一个比较大的topic，在这里一两句说不清楚，所以后续有时间再专门记录。 加载HAL so回想在AudioPolicyService启动的时候，会mDevicesFactoryHal-&gt;openDevice(name, &amp;dev),其实最终会调用DevicesFactory的loadAudioInterface，即打开audio.primary.default.so等lib。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int DevicesFactory::loadAudioInterface(const char *if_name, audio_hw_device_t **dev)&#123; const hw_module_t *mod; int rc; rc = hw_get_module_by_class(AUDIO_HARDWARE_MODULE_ID, if_name, &amp;mod); if (rc) &#123; ALOGE("%s couldn't load audio hw module %s.%s (%s)", __func__, AUDIO_HARDWARE_MODULE_ID, if_name, strerror(-rc)); goto out; &#125; rc = audio_hw_device_open(mod, dev); if (rc) &#123; ALOGE("%s couldn't open audio hw device in %s.%s (%s)", __func__, AUDIO_HARDWARE_MODULE_ID, if_name, strerror(-rc)); goto out; &#125; if ((*dev)-&gt;common.version &lt; AUDIO_DEVICE_API_VERSION_MIN) &#123; ALOGE("%s wrong audio hw device version %04x", __func__, (*dev)-&gt;common.version); rc = -EINVAL; audio_hw_device_close(*dev); goto out; &#125; return OK;out: *dev = NULL; return rc;&#125;// Methods from ::android::hardware::audio::V2_0::IDevicesFactory follow.Return&lt;void&gt; DevicesFactory::openDevice(IDevicesFactory::Device device, openDevice_cb _hidl_cb) &#123; audio_hw_device_t *halDevice; Result retval(Result::INVALID_ARGUMENTS); sp&lt;IDevice&gt; result; const char* moduleName = deviceToString(device); if (moduleName != nullptr) &#123; int halStatus = loadAudioInterface(moduleName, &amp;halDevice); if (halStatus == OK) &#123; if (device == IDevicesFactory::Device::PRIMARY) &#123; result = new PrimaryDevice(halDevice); &#125; else &#123; result = new ::android::hardware::audio::V2_0::implementation:: Device(halDevice); &#125; retval = Result::OK; &#125; else if (halStatus == -EINVAL) &#123; retval = Result::NOT_INITIALIZED; &#125; &#125; _hidl_cb(retval, result); return Void();&#125;]]></content>
      <categories>
        <category>Android Audio HAL</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Audio HIDL C++]]></title>
    <url>%2F2017%2F11%2F24%2FAndroid-Audio-HIDL-C%2B%2B%2F</url>
    <content type="text"><![CDATA[HAL接口定义语言（简称HIDL，发音为“hide-l”）是用于指定HAL和其用户之间的接口的一种接口描述语言 (IDL)。HIDL允许指定类型和方法调用（会汇集到接口和软件包中）。从更广泛的意义上来说，HIDL是用于在可以独立编译的代码库之间进行通信的系统。 HIDL旨在用于进程间通信 (IPC)。进程之间的通信经过Binder化。对于必须与进程相关联的代码库，还可以使用直通模式（在Java中不受支持）。 HIDL可指定数据结构和方法签名，这些内容会整理归类到接口（与类相似）中，而接口会汇集到软件包中。尽管HIDL具有一系列不同的关键字，但C++和Java程序员对HIDL的语法并不陌生。此外，HIDL还使用Java样式的注释。 HAL分类为了更好地实现模块化，Android 8.0对Android操作系统底层进行了重新架构。作为此变化的一部分，运行 Android 8.0的设备必须支持绑定式或直通式HAL： 绑定式HAL：以HAL接口定义语言 (HIDL) 表示的HAL。这些HAL取代了早期 Android 版本中使用的传统 HAL和旧版HAL。在绑定式HAL中，Android框架和HAL之间通过Binder进程间通信 (IPC) 调用进行通信。所有在推出时即搭载了Android 8.0或后续版本的设备都必须只支持绑定式HAL。 直通式HAL：以HIDL封装的传统HAL或旧版HAL。这些HAL封装了现有的HAL，可在绑定模式和 Same-Process（直通）模式下使用。升级到 Android 8.0 的设备可以使用直通式HAL。 HAL的发展历程HIDL接口具有客户端和服务器实现： HIDL接口的客户端实现是指通过在该接口上调用方法来使用该接口的代码。 服务器实现是指HIDL接口的实现，它可接收来自客户端的调用并返回结果（如有必要）。 在从libhardware HAL转换为HIDL HAL的过程中，HAL实现成为服务器，而调用HAL的进程则成为客户端。默认实现可提供直通和绑定式HAL，并可能会随着时间而发生变化： Audio HIDL客户端和服务端客户端创建libaudioflinger.so会依赖libaudiohal.so12LOCAL_SHARED_LIBRARIES += \ libaudiohal libaudiohal.so依赖android.hardware.audio@2.0.so12LOCAL_SHARED_LIBRARIES += \ android.hardware.audio@2.0 记得在AudioFlinger的启动过程中，在创建libaudiohal的DevicesFactoryHalHidl时有如下以一段代码，这里就是创建Audio HIDL的客户端。123456#include &lt;android/hardware/audio/2.0/IDevicesFactory.h&gt;DevicesFactoryHalHidl::DevicesFactoryHalHidl() &#123; mDevicesFactory = IDevicesFactory::getService(); ......&#125; 服务端创建生成可执行文件android.hardware.audio@2.0-service代表服务端，同样依赖于android.hardware.audio@2.0123LOCAL_MODULE := android.hardware.audio@2.0-serviceLOCAL_SHARED_LIBRARIES += \ android.hardware.audio@2.0 为了让HAL在直通模式下发挥作用（对于旧版设备），您必须具有HIDL_FETCH_IModuleName 函数（位于/system/lib(64)?/hw/android.hardware.package@3.0-impl(-$OPTIONAL_IDENTIFIER).so下），其中$OPTIONAL_IDENTIFIER是一个标识直通实现的字符串。比如对于Audio,在android.hardware.audio@2.0-impl.so中：123IDevicesFactory* HIDL_FETCH_IDevicesFactory(const char* /* name */) &#123; return new DevicesFactory();&#125; 接下来，使用功能填写存根并设置守护进程。守护进程代码（支持直通）示例：12345#include &lt;hidl/LegacySupport.h&gt;int main(int /* argc */, char* /* argv */ []) &#123; status = registerPassthroughServiceImplementation&lt;IDevicesFactory&gt;();&#125; registerPassthroughServiceImplementation将对提供的-impl库执行dlopen()操作，并将其作为绑定式服务提供。守护进程代码（对于纯绑定式服务）示例：1234int main(int /* argc */, char* /* argv */ []) &#123; Nfc nfc = new Nfc(); nfc-&gt;registerAsService();&#125; 此守护进程应该存在于$PACKAGE + “-service”（例如android.hardware.audio@2.0-service）中。HAL的特定类的sepolicy是属性hal_（例如 hal_audio))。您必须将此属性应用到运行特定HAL 的守护进程（如果同一进程提供多个HAL，则可以将多个属性应用到该进程）。 Audio HIDL接口软件包HIDL接口软件包位于hardware/interfaces或vendor/目录下（少数例外情况除外）。hardware/interfaces顶层会直接映射到android.hardware软件包命名空间；版本是软件包（而不是接口）命名空间下的子目录。 hidl-gen编译器会将.hal文件编译成一组.h和.cpp文件。这些自动生成的文件可用来编译客户端/服务器实现链接到的共享库。用于编译此共享库的Android.bp文件由hardware/interfaces/update-makefiles.sh 脚本自动生成。每次将新软件包添加到hardware/interfaces或在现有软件包中添加/移除.hal文件时，您都必须重新运行该脚本，以确保生成的共享库是最新的。 Auido HIDL接口定义对于Audio，.hal文件位于hardware/interfaces/audio/2.0下，我们看看客户端和服务端同时使用的IDevicesFactory接口，该定义在IDevicesFactory.hal中。1234567891011121314151617181920212223242526272829package android.hardware.audio@2.0;import android.hardware.audio.common@2.0;import IDevice;interface IDevicesFactory &#123; typedef android.hardware.audio@2.0::Result Result; enum Device : int32_t &#123; PRIMARY, A2DP, USB, R_SUBMIX, STUB &#125;; /** * Opens an audio device. To close the device, it is necessary to release * references to the returned device object. * * @param device device type. * @return retval operation completion status. Returns INVALID_ARGUMENTS * if there is no corresponding hardware module found, * NOT_INITIALIZED if an error occured while opening the hardware * module. * @return result the interface for the created device. */ openDevice(Device device) generates (Result retval, IDevice result);&#125;; HIDL接口转化为cpp如下是编译android.hardware.audio@2.0的Android.bp,由hidl-gen自动产生，不能手动编辑。IDevicesFactory.hal会生成DevicesFactoryAll.cpp，及IDevicesFactory.h，IHwDevicesFactory.h，BnHwDevicesFactory.h，BpHwDevicesFactory.h，BsDevicesFactory.h。生成的.h位于out/soong/.intermediates/hardware/interfaces/audio/2.0/android.hardware.audio@2.0_genc++_headers，生成的.cpp文件位于out/soong/.intermediates/hardware/interfaces/audio/2.0/android.hardware.audio@2.0_genc++。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109// This file is autogenerated by hidl-gen. Do not edit manually.filegroup &#123; name: "android.hardware.audio@2.0_hal", srcs: [ "types.hal", "IDevice.hal", "IDevicesFactory.hal", "IPrimaryDevice.hal", "IStream.hal", "IStreamIn.hal", "IStreamOut.hal", "IStreamOutCallback.hal", ],&#125;genrule &#123; name: "android.hardware.audio@2.0_genc++", tools: ["hidl-gen"], cmd: "$(location hidl-gen) -o $(genDir) -Lc++-sources -randroid.hardware:hardware/interfaces -randroid.hidl:system/libhidl/transport android.hardware.audio@2.0", srcs: [ ":android.hardware.audio@2.0_hal", ], out: [ "android/hardware/audio/2.0/types.cpp", "android/hardware/audio/2.0/DeviceAll.cpp", "android/hardware/audio/2.0/DevicesFactoryAll.cpp", "android/hardware/audio/2.0/PrimaryDeviceAll.cpp", "android/hardware/audio/2.0/StreamAll.cpp", "android/hardware/audio/2.0/StreamInAll.cpp", "android/hardware/audio/2.0/StreamOutAll.cpp", "android/hardware/audio/2.0/StreamOutCallbackAll.cpp", ],&#125;genrule &#123; name: "android.hardware.audio@2.0_genc++_headers", tools: ["hidl-gen"], cmd: "$(location hidl-gen) -o $(genDir) -Lc++-headers -randroid.hardware:hardware/interfaces -randroid.hidl:system/libhidl/transport android.hardware.audio@2.0", srcs: [ ":android.hardware.audio@2.0_hal", ], out: [ "android/hardware/audio/2.0/types.h", "android/hardware/audio/2.0/hwtypes.h", "android/hardware/audio/2.0/IDevice.h", "android/hardware/audio/2.0/IHwDevice.h", "android/hardware/audio/2.0/BnHwDevice.h", "android/hardware/audio/2.0/BpHwDevice.h", "android/hardware/audio/2.0/BsDevice.h", "android/hardware/audio/2.0/IDevicesFactory.h", "android/hardware/audio/2.0/IHwDevicesFactory.h", "android/hardware/audio/2.0/BnHwDevicesFactory.h", "android/hardware/audio/2.0/BpHwDevicesFactory.h", "android/hardware/audio/2.0/BsDevicesFactory.h", "android/hardware/audio/2.0/IPrimaryDevice.h", "android/hardware/audio/2.0/IHwPrimaryDevice.h", "android/hardware/audio/2.0/BnHwPrimaryDevice.h", "android/hardware/audio/2.0/BpHwPrimaryDevice.h", "android/hardware/audio/2.0/BsPrimaryDevice.h", "android/hardware/audio/2.0/IStream.h", "android/hardware/audio/2.0/IHwStream.h", "android/hardware/audio/2.0/BnHwStream.h", "android/hardware/audio/2.0/BpHwStream.h", "android/hardware/audio/2.0/BsStream.h", "android/hardware/audio/2.0/IStreamIn.h", "android/hardware/audio/2.0/IHwStreamIn.h", "android/hardware/audio/2.0/BnHwStreamIn.h", "android/hardware/audio/2.0/BpHwStreamIn.h", "android/hardware/audio/2.0/BsStreamIn.h", "android/hardware/audio/2.0/IStreamOut.h", "android/hardware/audio/2.0/IHwStreamOut.h", "android/hardware/audio/2.0/BnHwStreamOut.h", "android/hardware/audio/2.0/BpHwStreamOut.h", "android/hardware/audio/2.0/BsStreamOut.h", "android/hardware/audio/2.0/IStreamOutCallback.h", "android/hardware/audio/2.0/IHwStreamOutCallback.h", "android/hardware/audio/2.0/BnHwStreamOutCallback.h", "android/hardware/audio/2.0/BpHwStreamOutCallback.h", "android/hardware/audio/2.0/BsStreamOutCallback.h", ],&#125;cc_library_shared &#123; name: "android.hardware.audio@2.0", defaults: ["hidl-module-defaults"], generated_sources: ["android.hardware.audio@2.0_genc++"], generated_headers: ["android.hardware.audio@2.0_genc++_headers"], export_generated_headers: ["android.hardware.audio@2.0_genc++_headers"], vendor_available: true, shared_libs: [ "libhidlbase", "libhidltransport", "libhwbinder", "liblog", "libutils", "libcutils", "android.hardware.audio.common@2.0", ], export_shared_lib_headers: [ "libhidlbase", "libhidltransport", "libhwbinder", "libutils", "android.hardware.audio.common@2.0", ],&#125; IDevicesFactory.h - 描述C++类中的纯IDevicesFactory接口；它包含IDevicesFactory.hal文件中的IDevicesFactory接口中所定义的方法和类型，必要时会转换为C++类型。不包含与用于实现此接口的RPC机制（例如HwBinder）相关的详细信息。类的命名空间包含软件包名称和版本号，例如::android::hardware::audio::V2_0::IDevicesFactory。客户端和服务器都包含此标头：客户端用它来调用方法，服务器用它来实现这些方法。 IHwDevicesFactory.h - 头文件，其中包含用于对接口中使用的数据类型进行序列化的函数的声明。开发者不得直接包含其标头（它不包含任何类） BpHwDevicesFactory.h - 从IDevicesFactory继承的类，可描述接口的HwBinder代理（客户端）实现。开发者不得直接引用此类。 BnHwDevicesFactory.h - 保存对IDevicesFactory实现的引用的类，可描述接口的HwBinder存根（服务器端）实现。开发者不得直接引用此类。 DevicesFactoryAll.cpp - 包含HwBinder代理和HwBinder存根的实现的类。当客户端调用接口方法时，代理会自动从客户端封送参数，并将事务发送到绑定内核驱动程序，该内核驱动程序会将事务传送到另一端的存根（该存根随后会调用实际的服务器实现） BsDevicesFactory.h - 从IDevicesFactory继承的类，直通模式对IDevicesFactory的服务端实现。开发者不得直接引用此类。 这些文件的结构类似于由aidl-cpp生成的文件。独立于HIDL使用的RPC机制的唯一一个自动生成的文件是 IDevicesFactory.h，其他所有文件都与HIDL使用的HwBinder RPC机制相关联。因此，客户端和服务器实现不得直接引用除IDevicesFactory之外的任何内容。为了满足这项要求，请只包含IDevicesFactory.h并链接到生成的共享库。]]></content>
      <categories>
        <category>Android Audio HAL</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AudioPolicyService启动过程]]></title>
    <url>%2F2017%2F11%2F10%2FAudioPolicyService%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[AudioPolicyService在Audio系统另一个重要的服务，是音频策略的制定者，负责音频设备切换的策略抉择、音量调节策略等。本文基于Android 8.0的代码，记录了AudioPolicyService启动的过程，介绍了其中几个比较关键的点，希望以后自己看到此文能快速回想起AudioPolicyService的启动过程。其代码位于frameworks/av/services/audiopolicy。 audiopolicy的代码结构 service目录是AudioPolicyService、AudioPolicyClient、AudioCommandThread及AudioPolicyEffects的定义及实现。 managerdefault目录提供AudioPolicyManager的基本实现。 manager目录中是一个工厂类可以根据需要生产所需的AudioPolicyManager，一般各个厂商都会自己实现自己的AudioPolicyManager。 engine目录定义了AudioPolicyManagerInterface和AudioPolicyManagerObserver接口，AudioPolicyManagerInterface由Policy Engine实现，AudioPolicyManagerObserver这个观察者由AudioPolicyManager实现，以供Engine访问。 engineconfigure和enginedefault目录是Policy Engine的两种实现，可以根据需要选择其中一种。 config目录存放audio policy及音量曲线的config文件。 common目录下定义公共代码。audio_policy.conf是旧版本的audio policy config文件。 AudioPolicyInterface.h定义了AudioPolicyInterface和AudioPolicyClientInterface接口，AudioPolicyInterface由AuidoPolicyManager实现，特定平台AuidoPolicyManager通过AudioPolicyClientInterface接口的实现者AudioPolicyClient控制音频的输入输出。AudioPolicyService初始化从Android 8.0的code发现，基本流程还是和之前一样，分别创建了ApmTone、ApmAudio、ApmOutput三个AudioCommandThread线程，分别用于播放tone音、执行audio命令和执行输出命令，创建AudioPolicyClient，创建AudioPolicyManager以及创建AudioPolicyEffects。但已经完全移除了对旧版本的AUDIO_POLICY_HARDWARE_MODULE_ID的支持（不再加载audio_policy.default.so库得到audio_policy_module模块），完全使用新模式。12345678910111213141516171819202122232425262728AudioPolicyService::AudioPolicyService() : BnAudioPolicyService(), mpAudioPolicyDev(NULL), mpAudioPolicy(NULL), mAudioPolicyManager(NULL), mAudioPolicyClient(NULL), mPhoneState(AUDIO_MODE_INVALID)&#123;&#125;void AudioPolicyService::onFirstRef()&#123; &#123; Mutex::Autolock _l(mLock); // start tone playback thread mTonePlaybackThread = new AudioCommandThread(String8("ApmTone"), this); // start audio commands thread mAudioCommandThread = new AudioCommandThread(String8("ApmAudio"), this); // start output activity command thread mOutputCommandThread = new AudioCommandThread(String8("ApmOutput"), this); mAudioPolicyClient = new AudioPolicyClient(this); mAudioPolicyManager = createAudioPolicyManager(mAudioPolicyClient); &#125; // load audio processing modules sp&lt;AudioPolicyEffects&gt;audioPolicyEffects = new AudioPolicyEffects(); &#123; Mutex::Autolock _l(mLock); mAudioPolicyEffects = audioPolicyEffects; &#125;&#125; 这些类之间的大致关系如下（AudioPolicyClient和AudioCommandThread都为AudioPolicyService的内部类）：AudioPolicyService的初始化大致分为3步：1.创建三个AudioCommandThread（mTonePlaybackThread，mAudioCommandThread和mOutputCommandThread）2.初始化AudioPolicyManager 2.1 加载并解析audio_policy_configuration.xml 2.2 加载对应的HW module 2.3 初始化Policy Engine 2.4 打开输入输出 2.5 确保所有可用输入输出设备和默认输出设备真正可用3.初始化AudioPolicyEffects AudioCommandThread线程AudioCommandThread采用异步方式来执行audio command，当需要执行上表中的命令时，首先将命令投递到AudioCommandThread的mAudioCommands命令向量表中，然后通过mWaitWorkCV.signal()唤醒AudioCommandThread线程，被唤醒的AudioCommandThread线程执行完command后，又通过mWaitWorkCV.waitRelative(mLock, waitTime)睡眠等待命令到来。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879void AudioPolicyService::AudioCommandThread::onFirstRef()&#123; run(mName.string(), ANDROID_PRIORITY_AUDIO);&#125;status_t AudioPolicyService::AudioCommandThread::volumeCommand(audio_stream_type_t stream, float volume, audio_io_handle_t output, int delayMs)&#123; sp&lt;AudioCommand&gt; command = new AudioCommand(); command-&gt;mCommand = SET_VOLUME; sp&lt;VolumeData&gt; data = new VolumeData(); data-&gt;mStream = stream; data-&gt;mVolume = volume; data-&gt;mIO = output; command-&gt;mParam = data; command-&gt;mWaitStatus = true; return sendCommand(command, delayMs);&#125;bool AudioPolicyService::AudioCommandThread::threadLoop()&#123; nsecs_t waitTime = -1; mLock.lock(); while (!exitPending()) &#123; sp&lt;AudioPolicyService&gt; svc; while (!mAudioCommands.isEmpty() &amp;&amp; !exitPending()) &#123; nsecs_t curTime = systemTime(); // commands are sorted by increasing time stamp: execute them from index 0 and up if (mAudioCommands[0]-&gt;mTime &lt;= curTime) &#123; sp&lt;AudioCommand&gt; command = mAudioCommands[0]; mAudioCommands.removeAt(0); mLastCommand = command; switch (command-&gt;mCommand) &#123; ...... case SET_VOLUME: &#123; VolumeData *data = (VolumeData *)command-&gt;mParam.get(); ALOGV("AudioCommandThread() processing set volume stream %d, \ volume %f, output %d", data-&gt;mStream, data-&gt;mVolume, data-&gt;mIO); command-&gt;mStatus = AudioSystem::setStreamVolume(data-&gt;mStream, data-&gt;mVolume, data-&gt;mIO); &#125;break; ...... &#125; ..... &#125; else &#123; waitTime = mAudioCommands[0]-&gt;mTime - curTime; break; &#125; &#125; ...... // At this stage we have either an empty command queue or the first command in the queue // has a finite delay. So unless we are exiting it is safe to wait. if (!exitPending()) &#123; ALOGV("AudioCommandThread() going to sleep"); if (waitTime == -1) &#123; mWaitWorkCV.wait(mLock); &#125; else &#123; mWaitWorkCV.waitRelative(mLock, waitTime); &#125; &#125; &#125; ...... mLock.unlock(); return false;&#125; AudioCommandThread是AudioPolicyService的内部类，AudioCommandThread在内部又定义了AudioCommand及AudioCommandData关系如下。 AudioPolicyManager初始化12345678910111213141516171819202122232425262728293031323334AudioPolicyManager::AudioPolicyManager(AudioPolicyClientInterface *clientInterface) : mLimitRingtoneVolume(false), mLastVoiceVolume(-1.0f), mA2dpSuspended(false), mAudioPortGeneration(1), mBeaconMuteRefCount(0), mBeaconPlayingRefCount(0), mBeaconMuted(false), mTtsOutputAvailable(false), mMasterMono(false), mMusicEffectOutput(AUDIO_IO_HANDLE_NONE), mHasComputedSoundTriggerSupportsConcurrentCapture(false)&#123; mUidCached = getuid(); mpClientInterface = clientInterface; ...... // audio policy config加载 // 初始化Policy Engine for (size_t i = 0; i &lt; mHwModules.size(); i++) &#123; // 加载所有的HW module ...... // 打开音频输入输出 &#125; // 确保所有可用输入输出设备真正可用 ...... // 确保默认输出设备真正可用 ALOGE_IF((mPrimaryOutput == 0), "Failed to open primary output"); updateDevicesAndOutputs();&#125; audio policy config加载进入AudioPolicyManager构造函数，会首先加载audio policy config文件，对于旧版本使用audio_policy.conf，在代码中定义音量曲线，对于新版本使用audio_policy_configuration.xml。对于Android 8.0使用新版本，这个文件一般会位于/odm/etc或/vendor/etc，同时解析音量曲线xml（audio_policy_volumes.xml和default_volume_tables.xml）,比起之前的硬编码音量曲线，灵活性更好。1234567891011121314151617181920#ifdef USE_XML_AUDIO_POLICY_CONF mVolumeCurves = new VolumeCurvesCollection(); AudioPolicyConfig config(mHwModules, mAvailableOutputDevices, mAvailableInputDevices, mDefaultOutputDevice, speakerDrcEnabled, static_cast&lt;VolumeCurvesCollection *&gt;(mVolumeCurves)); if (deserializeAudioPolicyXmlConfig(config) != NO_ERROR) &#123;#else mVolumeCurves = new StreamDescriptorCollection(); AudioPolicyConfig config(mHwModules, mAvailableOutputDevices, mAvailableInputDevices, mDefaultOutputDevice, speakerDrcEnabled); if ((ConfigParsingUtils::loadConfig(AUDIO_POLICY_VENDOR_CONFIG_FILE, config) != NO_ERROR) &amp;&amp; (ConfigParsingUtils::loadConfig(AUDIO_POLICY_CONFIG_FILE, config) != NO_ERROR)) &#123;#endif ALOGE("could not load audio policy configuration file, setting defaults"); config.setDefault(); &#125; // must be done after reading the policy (since conditionned by Speaker Drc Enabling) // xml模式时这里是一个空函数无实现 mVolumeCurves-&gt;initializeVolumeCurves(speakerDrcEnabled); 当执行完deserializeAudioPolicyXmlConfig，会得到mHwModules对应各个Audio HAL模块、mAvailableOutputDevices可用的输出设备、mAvailableInputDevices可用的输入设备、mDefaultOutputDevice默认输出设备、mVolumeCurves音量曲线及speakerDrcEnabled。 audio_policy_configuration.xml同时定义了多个audio接口(HwModules)，每一个audio接口包含若干routes（通路）、devicesPorts（设备）和mixPorts（音频流），而每个mixPorts又包含多个input和output流，每个input和output流又同时支持多种输入输出模式，每种输入输出模式又支持若干种设备。mixPorts：listing all output and input streams exposed by the audio HAL.routes：list of possible connections between input and output devices or between stream and devices.devicePorts：a list of device descriptors for all input and output devices accessible via this module.This contains both permanently attached devices and removable devices.每个stream type会分为四种device category：DEVICE_CATEGORY_HEADSET，DEVICE_CATEGORY_SPEAKER，DEVICE_CATEGORY_EARPIECE及DEVICE_CATEGORY_EXT_MEDIA来定义音量曲线，定义的形式如下，一样是分段定义，在每一段中定义不同的衰减值以控制音量的大小。It contains a list of points of this curve expressing the attenuation in Millibels for a given volume index from 0 to 100.123456&lt;volume stream="AUDIO_STREAM_VOICE_CALL" deviceCategory="DEVICE_CATEGORY_HEADSET"&gt; &lt;point&gt;0,-4200&lt;/point&gt; &lt;point&gt;33,-2800&lt;/point&gt; &lt;point&gt;66,-1400&lt;/point&gt; &lt;point&gt;100,0&lt;/point&gt;&lt;/volume&gt; 初始化Policy Engine这里也算一个观察者模式吧，EngineInstance是单例模式，通过EngineInstance创建AudioPolicyManagerInterface，从而创建Policy Engine，然后设置观察者。12345678910111213141516// Once policy config has been parsed, retrieve an instance of the engine and initialize it. audio_policy::EngineInstance *engineInstance = audio_policy::EngineInstance::getInstance(); if (!engineInstance) &#123; ALOGE("%s: Could not get an instance of policy engine", __FUNCTION__); return; &#125; // Retrieve the Policy Manager Interface mEngine = engineInstance-&gt;queryInterface&lt;AudioPolicyManagerInterface&gt;(); if (mEngine == NULL) &#123; ALOGE("%s: Failed to get Policy Engine Interface", __FUNCTION__); return; &#125; mEngine-&gt;setObserver(this); status_t status = mEngine-&gt;initCheck(); (void) status; ALOG_ASSERT(status == NO_ERROR, "Policy engine not initialized(err=%d)", status); 其大致关系如下。 加载HW Module根据audio policy config加载的HwModule真正加载HAL层的HW module。123456789101112// mAvailableOutputDevices and mAvailableInputDevices now contain all attached devices// open all output streams needed to access attached devicesaudio_devices_t outputDeviceTypes = mAvailableOutputDevices.types();audio_devices_t inputDeviceTypes = mAvailableInputDevices.types() &amp; ~AUDIO_DEVICE_BIT_IN;for (size_t i = 0; i &lt; mHwModules.size(); i++) &#123; mHwModules[i]-&gt;mHandle = mpClientInterface-&gt;loadHwModule(mHwModules[i]-&gt;getName()); if (mHwModules[i]-&gt;mHandle == 0) &#123; continue; &#125; ......&#125; 从如上代码看出，会执行mpClientInterface-&gt;loadHwModule，即调用AudioPolicyClient的loadHwModule函数，又会转到AudioFlinger的loadHwModule。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859audio_module_handle_t AudioPolicyService::AudioPolicyClient::loadHwModule(const char *name)&#123; sp&lt;IAudioFlinger&gt; af = AudioSystem::get_audio_flinger(); if (af == 0) &#123; ALOGW("%s: could not get AudioFlinger", __func__); return AUDIO_MODULE_HANDLE_NONE; &#125; return af-&gt;loadHwModule(name);&#125;audio_module_handle_t AudioFlinger::loadHwModule(const char *name)&#123; if (name == NULL) &#123; return AUDIO_MODULE_HANDLE_NONE; &#125; if (!settingsAllowed()) &#123; return AUDIO_MODULE_HANDLE_NONE; &#125; Mutex::Autolock _l(mLock); return loadHwModule_l(name);&#125;// loadHwModule_l() must be called with AudioFlinger::mLock heldaudio_module_handle_t AudioFlinger::loadHwModule_l(const char *name)&#123; for (size_t i = 0; i &lt; mAudioHwDevs.size(); i++) &#123; if (strncmp(mAudioHwDevs.valueAt(i)-&gt;moduleName(), name, strlen(name)) == 0) &#123; ALOGW("loadHwModule() module %s already loaded", name); return mAudioHwDevs.keyAt(i); &#125; &#125; sp&lt;DeviceHalInterface&gt; dev; int rc = mDevicesFactoryHal-&gt;openDevice(name, &amp;dev); if (rc) &#123; ALOGE("loadHwModule() error %d loading module %s", rc, name); return AUDIO_MODULE_HANDLE_NONE; &#125; ...... // Check and cache this HAL's level of support for master mute and master // volume. If this is the first HAL opened, and it supports the get // methods, use the initial values provided by the HAL as the current // master mute and volume settings. ...... audio_module_handle_t handle = (audio_module_handle_t) nextUniqueId(AUDIO_UNIQUE_ID_USE_MODULE); mAudioHwDevs.add(handle, new AudioHwDevice(handle, name, dev, flags)); ALOGI("loadHwModule() Loaded %s audio interface, handle %d", name, handle); return handle;&#125; mDevicesFactoryHal-&gt;openDevice(name, &amp;dev),从前面AudioFlinger的启动，我们知道mDevicesFactoryHal是HAL进程的客户端，对于Android 8.0加载HAL so文件已经移到HAL进程中，不再与audioserver处于同一个进程中。在AudioFlinger中使用AudioHwDevice代表HW Module，AudioHwDevice会封装audio_module_handle_t和DeviceHalInterface，并以audio_module_handle_t为key将其保存在AudioFlinger的mAudioHwDevs中，以供后续查询。到这里就加载系统的音频接口就加载完了，我们大致可以得出如下结果。 打开音频输出这里的输出，即mixPorts中outputs，也就是mHwModules中所有OutputProfile（IOProfile），代表了音频输出流。所以会遍历mHwModules中所有OutputProfile，然后SwAudioOutputDescriptor来描述每一个output，最终保存在以audio_io_handle_t为key的mOutputs中，以供后续查询。不过这里会除了AUDIO_OUTPUT_FLAG_DIRECT，AUDIO_OUTPUT_FLAG_DIRECT的output会在使用的时候打开，不会预先open。在打开输出设备后还会标记可用输出设备的可用情况，以备后续确认可用输出设备真正可用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// open all output streams needed to access attached devices// except for direct output streams that are only opened when they are actually// required by an app.// This also validates mAvailableOutputDevices listfor (size_t j = 0; j &lt; mHwModules[i]-&gt;mOutputProfiles.size(); j++)&#123; const sp&lt;IOProfile&gt; outProfile = mHwModules[i]-&gt;mOutputProfiles[j]; if (!outProfile-&gt;hasSupportedDevices()) &#123; continue; &#125; if ((outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_TTS) != 0) &#123; mTtsOutputAvailable = true; &#125; if ((outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_DIRECT) != 0) &#123; continue; &#125; audio_devices_t profileType = outProfile-&gt;getSupportedDevicesType(); if ((profileType &amp; mDefaultOutputDevice-&gt;type()) != AUDIO_DEVICE_NONE) &#123; profileType = mDefaultOutputDevice-&gt;type(); &#125; else &#123; // chose first device present in profile's SupportedDevices also part of // outputDeviceTypes profileType = outProfile-&gt;getSupportedDeviceForType(outputDeviceTypes); &#125; if ((profileType &amp; outputDeviceTypes) == 0) &#123; continue; &#125; sp&lt;SwAudioOutputDescriptor&gt; outputDesc = new SwAudioOutputDescriptor(outProfile, mpClientInterface); const DeviceVector &amp;supportedDevices = outProfile-&gt;getSupportedDevices(); const DeviceVector &amp;devicesForType = supportedDevices.getDevicesFromType(profileType); String8 address = devicesForType.size() &gt; 0 ? devicesForType.itemAt(0)-&gt;mAddress : String8(""); outputDesc-&gt;mDevice = profileType; audio_config_t config = AUDIO_CONFIG_INITIALIZER; config.sample_rate = outputDesc-&gt;mSamplingRate; config.channel_mask = outputDesc-&gt;mChannelMask; config.format = outputDesc-&gt;mFormat; audio_io_handle_t output = AUDIO_IO_HANDLE_NONE; status_t status = mpClientInterface-&gt;openOutput(outProfile-&gt;getModuleHandle(), &amp;output, &amp;config, &amp;outputDesc-&gt;mDevice, address, &amp;outputDesc-&gt;mLatency, outputDesc-&gt;mFlags); if (status != NO_ERROR) &#123; ...... &#125; else &#123; outputDesc-&gt;mSamplingRate = config.sample_rate; outputDesc-&gt;mChannelMask = config.channel_mask; outputDesc-&gt;mFormat = config.format; for (size_t k = 0; k &lt; supportedDevices.size(); k++) &#123; ssize_t index = mAvailableOutputDevices.indexOf(supportedDevices[k]); // give a valid ID to an attached device once confirmed it is reachable if (index &gt;= 0 &amp;&amp; !mAvailableOutputDevices[index]-&gt;isAttached()) &#123; mAvailableOutputDevices[index]-&gt;attach(mHwModules[i]); &#125; &#125; if (mPrimaryOutput == 0 &amp;&amp; outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_PRIMARY) &#123; mPrimaryOutput = outputDesc; &#125; addOutput(output, outputDesc); setOutputDevice(outputDesc, outputDesc-&gt;mDevice, true, 0, NULL, address.string()); &#125;&#125; 我们看到会使用到mpClientInterface打开输出，即调用AudioPolicyClient的openOutput，即调用AudioFlinger的openOutput及openOutput_l。首先调用findSuitableHwDev_l查询合适的AudioHwDevice，即通过audio_module_handle_t在之前加载的mAudioHwDevs中去除对应的AudioHwDevice，调用AudioHwDevice的openOutputStream得到AudioStreamOut，然后根据output flag创建相应的Thread，最后以audio_io_handle_t为key将Thread保存在mPlaybackThreads和mMmapThreads。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798sp&lt;AudioFlinger::ThreadBase&gt; AudioFlinger::openOutput_l(audio_module_handle_t module, audio_io_handle_t *output, audio_config_t *config, audio_devices_t devices, const String8&amp; address, audio_output_flags_t flags)&#123; AudioHwDevice *outHwDev = findSuitableHwDev_l(module, devices); if (outHwDev == NULL) &#123; return 0; &#125; if (*output == AUDIO_IO_HANDLE_NONE) &#123; *output = nextUniqueId(AUDIO_UNIQUE_ID_USE_OUTPUT); &#125; else &#123; return 0; &#125; mHardwareStatus = AUDIO_HW_OUTPUT_OPEN; // FOR TESTING ONLY: ...... AudioStreamOut *outputStream = NULL; status_t status = outHwDev-&gt;openOutputStream( &amp;outputStream, *output, devices, flags, config, address.string()); mHardwareStatus = AUDIO_HW_IDLE; if (status == NO_ERROR) &#123; if (flags &amp; AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) &#123; sp&lt;MmapPlaybackThread&gt; thread = new MmapPlaybackThread(this, *output, outHwDev, outputStream, devices, AUDIO_DEVICE_NONE, mSystemReady); mMmapThreads.add(*output, thread); ALOGV("openOutput_l() created mmap playback thread: ID %d thread %p", *output, thread.get()); return thread; &#125; else &#123; sp&lt;PlaybackThread&gt; thread; if (flags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) &#123; thread = new OffloadThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created offload output: ID %d thread %p", *output, thread.get()); &#125; else if ((flags &amp; AUDIO_OUTPUT_FLAG_DIRECT) || !isValidPcmSinkFormat(config-&gt;format) || !isValidPcmSinkChannelMask(config-&gt;channel_mask)) &#123; thread = new DirectOutputThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created direct output: ID %d thread %p", *output, thread.get()); &#125; else &#123; thread = new MixerThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created mixer output: ID %d thread %p", *output, thread.get()); &#125; mPlaybackThreads.add(*output, thread); return thread; &#125; &#125; return 0;&#125;status_t AudioFlinger::openOutput(audio_module_handle_t module, audio_io_handle_t *output, audio_config_t *config, audio_devices_t *devices, const String8&amp; address, uint32_t *latencyMs, audio_output_flags_t flags)&#123; if (devices == NULL || *devices == AUDIO_DEVICE_NONE) &#123; return BAD_VALUE; &#125; Mutex::Autolock _l(mLock); sp&lt;ThreadBase&gt; thread = openOutput_l(module, output, config, *devices, address, flags); if (thread != 0) &#123; if ((flags &amp; AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) == 0) &#123; PlaybackThread *playbackThread = (PlaybackThread *)thread.get(); *latencyMs = playbackThread-&gt;latency(); // notify client processes of the new output creation playbackThread-&gt;ioConfigChanged(AUDIO_OUTPUT_OPENED); // the first primary output opened designates the primary hw device if ((mPrimaryHardwareDev == NULL) &amp;&amp; (flags &amp; AUDIO_OUTPUT_FLAG_PRIMARY)) &#123; ALOGI("Using module %d as the primary audio interface", module); mPrimaryHardwareDev = playbackThread-&gt;getOutput()-&gt;audioHwDev; AutoMutex lock(mHardwareLock); mHardwareStatus = AUDIO_HW_SET_MODE; mPrimaryHardwareDev-&gt;hwDevice()-&gt;setMode(mMode); mHardwareStatus = AUDIO_HW_IDLE; &#125; &#125; else &#123; MmapThread *mmapThread = (MmapThread *)thread.get(); mmapThread-&gt;ioConfigChanged(AUDIO_OUTPUT_OPENED); &#125; return NO_ERROR; &#125; return NO_INIT;&#125; 我们可以看到在AudioPolicyManager中有mOutputs以audio_io_handle_t为key保存SwAudioOutputDescriptor，而在AudioFlinger中mPlaybackThreads和mMmapThreads以audio_io_handle_t保存线程，所以我们可以得出如下关系图。 打开音频输入打开音频输入和打开音频输出很类似，只是将SwAudioOutputDescriptor、PlaybackThread及AudioStreamOut换成了AudioInputDescriptor、RecordThread及AudioStreamIn，这里就一笔带过。 确保可用输入输出和默认输出真正可用无其他。主要是移除不可达设备。1234567891011121314151617181920212223242526272829303132333435363738// make sure all attached devices have been allocated a unique ID// 确保所有可用输出设备真正可用for (size_t i = 0; i &lt; mAvailableOutputDevices.size();) &#123; if (!mAvailableOutputDevices[i]-&gt;isAttached()) &#123; ALOGW("Output device %08x unreachable", mAvailableOutputDevices[i]-&gt;type()); mAvailableOutputDevices.remove(mAvailableOutputDevices[i]); continue; &#125; // The device is now validated and can be appended to the available // devices of the engine // 目前不做任何处理 mEngine-&gt;setDeviceConnectionState(mAvailableOutputDevices[i], AUDIO_POLICY_DEVICE_STATE_AVAILABLE); i++;&#125;// 确保所有可用输入设备真正可用for (size_t i = 0; i &lt; mAvailableInputDevices.size();) &#123; if (!mAvailableInputDevices[i]-&gt;isAttached()) &#123; ALOGW("Input device %08x unreachable", mAvailableInputDevices[i]-&gt;type()); mAvailableInputDevices.remove(mAvailableInputDevices[i]); continue; &#125; // The device is now validated and can be appended to the available devices of the engine // 目前不做任何处理 mEngine-&gt;setDeviceConnectionState(mAvailableInputDevices[i], AUDIO_POLICY_DEVICE_STATE_AVAILABLE); i++;&#125;// make sure default device is reachable// 确保默认输出设备真正可用if (mDefaultOutputDevice == 0 || mAvailableOutputDevices.indexOf(mDefaultOutputDevice) &lt; 0) &#123; ALOGE("Default device %08x is unreachable", mDefaultOutputDevice-&gt;type());&#125;ALOGE_IF((mPrimaryOutput == 0), "Failed to open primary output");updateDevicesAndOutputs(); AudioPolicyEffects初始化对于音效策略，类似会先加载audio_effects.conf，这个文件可能位于system/etc/或者vendor/etc/。123456789AudioPolicyEffects::AudioPolicyEffects()&#123; // load automatic audio effect modules if (access(AUDIO_EFFECT_VENDOR_CONFIG_FILE, R_OK) == 0) &#123; loadAudioEffectConfig(AUDIO_EFFECT_VENDOR_CONFIG_FILE); &#125; else if (access(AUDIO_EFFECT_DEFAULT_CONFIG_FILE, R_OK) == 0) &#123; loadAudioEffectConfig(AUDIO_EFFECT_DEFAULT_CONFIG_FILE); &#125;&#125; 这个文件的格式如下。123456789101112131415161718192021# List of effect libraries to load. Each library element must contain a "path" element# giving the full path of the library .so file.# libraries &#123;# &lt;lib name&gt; &#123;# path &lt;lib path&gt;# &#125;# &#125;# list of effects to load. Each effect element must contain a "library" and a "uuid" element.# The value of the "library" element must correspond to the name of one library element in the# "libraries" element.# The name of the effect element is indicative, only the value of the "uuid" element# designates the effect.# The uuid is the implementation specific UUID as specified by the effect vendor. This is not the# generic effect type UUID.# effects &#123;# &lt;fx name&gt; &#123;# library &lt;lib name&gt;# uuid &lt;effect uuid&gt;# &#125;# ...# &#125; 到这里AudioPolicyService的启动流程已经完结，且篇幅已经挺长，其他的知识点，学习到时再补上。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AudioFlinger启动过程]]></title>
    <url>%2F2017%2F11%2F09%2FAudioFlinger%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[AudioFlinger以media.audio_flinger为名注册到ServiceManager，是Android Audio系统的一个核心服务，是音频策略的执行者，负责输入输出流设备的管理及音频流数据的处理传输。本文以Android 8.0的代码为基础，记录了其启动过程以及AudioFlinger主要类的关系。其代码位于frameworks/av/services/audioflinger。 AudioFlinger的启动过程Android 8.0中与7.0相比，在初始化过程中，主要是实例化了mDevicesFactoryHal和mEffectsFactoryHal，作为HAL进程的客户端与HAL进程交互。12345678910111213141516171819202122232425AudioFlinger::AudioFlinger() //变量初始化 : BnAudioFlinger(), mMediaLogNotifier(new AudioFlinger::MediaLogNotifier()), mPrimaryHardwareDev(NULL), mAudioHwDevs(NULL), mHardwareStatus(AUDIO_HW_IDLE), mMasterVolume(1.0f), mMasterMute(false), // mNextUniqueId(AUDIO_UNIQUE_ID_USE_MAX), mMode(AUDIO_MODE_INVALID), mBtNrecIsOff(false), mIsLowRamDevice(true), mIsDeviceTypeKnown(false), mGlobalEffectEnableTime(0), mSystemReady(false)&#123; ...... mDevicesFactoryHal = DevicesFactoryHalInterface::create(); mEffectsFactoryHal = EffectsFactoryHalInterface::create(); ......&#125; 这里我们主要看一下DevicesFactoryHalInterface关系图。EffectsFactoryHalInterface也是类似的情况。阅读每个类的代码实现，我们发现只有DevicesFactoryHalHybrid实现了DevicesFactoryHalInterface接口的create()函数，所以这里会创建DevicesFactoryHalHybrid实例，而DevicesFactoryHalHybrid会创建DevicesFactoryHalLocal和DevicesFactoryHalHidl实例。DevicesFactoryHalLocal用于直接加载HAL的lib，是为了兼容8.0之前的版本，而DevicesFactoryHalHidl通过binder通信从hwservicemanager中返回IDevicesFactory实例，通过IDevicesFactory的openDevice函数返回具体的Device，并且用DeviceHalHidl封装返回的Device，这里不再会直接加载HAL的lib，后续和HAL的通信完全通过IDevicesFactory接口，具体在AudioPolicyService加载HW module时会更清楚明白。 第一次初始化还会执行onFirstRef()，创建PatchPanel实例且将AudioFlinger实例传入PatchPanel，设置Audio Mode为AUDIO_MODE_NORMAL,并将自己保存在全局变量gAudioFlinger。123456789101112void AudioFlinger::onFirstRef()&#123; Mutex::Autolock _l(mLock); ...... mPatchPanel = new PatchPanel(this); mMode = AUDIO_MODE_NORMAL; gAudioFlinger = this;&#125; Mutex是互斥类，用于多线程访问同一个资源的时候，保证一次只有一个线程能访问该资源。它的工作原理是某一个线程要访问公共资源的时候先锁定这个Mutex，完成操作之后对Mutex解锁，在此期间如果有其它的线程也要访问公共资源，它就先要去锁Mutex，当它发现Mutex已经被锁住了，那么这个线程就是阻塞在那儿。等Mutex解锁之后所有阻塞在Mutex的线程都会醒来，只有第一个醒来的会抢到Mutex，其它没有抢到的发现自己晚了一步，只能继续阻塞在那儿，等待下次机会。Mutex源码位置/system/core/libutils/include/utils。 为了简化一般的Mutex操作，在class Mutex中定义了一个内部类Autolock，它利用{}作用域实现自动解锁，看一下它的构造函数就知道了。12345678class Autolock &#123; public: inline explicit Autolock(Mutex&amp; mutex) : mLock(mutex) &#123; mLock.lock(); &#125; inline explicit Autolock(Mutex* mutex) : mLock(*mutex) &#123; mLock.lock(); &#125; inline ~Autolock() &#123; mLock.unlock(); &#125; private: Mutex&amp; mLock;&#125;; 我们知道在{}中创建的变量，变开这个大括号时就要销毁，于是就自动调用析构函数了。 AudioFlinger中放音录音线程AudioFlinger作为音频的核心服务，主要责任是负责放音与录音，下面我们可以大致看看放音与录音线程的关系，在AudioPolicyServic启动过程中我们会看到这些线程的创建。 ThreadBase：ThreadBase以Thread为基类，而又是PlaybackThread、RecordThread和MmapThread的基类。 RecordThread：音频录音线程，负责音频的录音，没有子类。 PlaybackThread：代表放音线程，有两个直接子类MixerThread和DirectOutputThread。 MixerThread：混音放音线程，有子类DuplicatingThread，负责处理标识为AUDIO_OUTPUT_FLAG_PRIMARY、AUDIO_OUTPUT_FLAG_FAST、AUDIO_OUTPUT_FLAG_DEEP_BUFFER的音频流，MixerThread 可以把多个音轨的数据混音后再输出。 DirectOutputThread：直接输出放音线程，有子类OffloadThread，负责处理标识为AUDIO_OUTPUT_FLAG_DIRECT的音频流，这种音频流数据不需要软件混音，直接输出到音频设备即可。 DuplicatingThread：复制输出放音线程，负责复制音频流数据到其他输出设备，使用场景如主声卡设备、蓝牙耳机设备、USB声卡设备同时输出。 OffloadThread：硬解回放线程，负责处理标识为AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD的音频流，这种音频流未经软件解码的（一般是MP3、AAC等格式的数据），需要输出到硬件解码器，由硬件解码器解码成PCM 数据。 MmapThread：这个线程是Android 8.0新加入的，用于低延迟的放音与录音，与AAudio有关系，有MmapPlaybackThread和MmapCaptureThread两个子类。 MmapPlaybackThread：MMAP放音线程，负责处理标识为AUDIO_OUTPUT_FLAG_MMAP_NOIRQ的音频流。 MmapcaptureThread：MMAP录音线程，负责处理标识为AUDIO_INPUT_FLAG_MMAP_NOIRQ的音频流。AudioFlinger中TracksTrack：音轨，是AudioFlinger中另一个重要的将角色，下面我们可以看看其关系。对于播放对应Track，OutputTrack，TrackHandle及BnAudioTrack，TrackHandle和BnAudioTrack主要用于和Client端Binder通信，真正代表输出音轨的为Track。同样对应录音音轨的是RecordTrack，RecordHandle及BnAudioRecord，RecordHandle和BnAudioRecord也用于Binder通信，真正录音音轨为RecordTrack。而对于MmapTrack稍微不太样，而是定义通用接口MmapStreamInterface封装MmapThread，再封装MmapTrack，不是通过XXXHandle继承BnXXX，这也许是出于latency上的考虑。AudioFlinger中的Streams我们看到在AudioFlinger中以AudioHwDevice封装HAL的DeviceHalHidl，而DeviceHalHidl封装从HAL返回的具体的Device，这就和HAL层的so文件连接在一起，且AudioHwDevice直接或间接依赖AudioStreamOut和AudioStreanIn这样也和HAL层中stream关联上，后续打开音频输入输出以及打开输入音频流及输出音频流做好准备。具体我们可以在AudioPolicyService启动的时候看的更清楚。AudioFlinger中还有很多其他的知识点，后续学到时再慢慢补上。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Audio Server启动]]></title>
    <url>%2F2017%2F11%2F08%2FAndroid-Audio-Server%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[Android audioserver是Audio系统native的服务，也是连接Audio Framework和Audio HAL的一个纽带，其中包含了AudioFlinger、AudioPolicyService、AAudioService、RadioService、SoundTriggerHwService等服务。源代码位于frameworks/av/media/audioserver 从Android 7.0开始，Audio相关的service从mediaserver中转移到audioserver，把audio，camera及mediaplayerservice做了一个拆分，这样不会显得臃肿、职能更加独立且安全性更高。拆分之后audioserver还是一个native service，还是从init进程中启动，如下是其在audioserver.rc中的启动代码。 12345678910service audioserver /system/bin/audioserver class main # audioserver和class main行为一致 user audioserver # 用户归属，uid：AID_AUDIOSERVER # media gid needed for /dev/fm (radio) and for /data/misc/media (tee) group audio camera drmrpc inet media mediadrm net_bt \ net_bt_admin net_bw_acct oem_2901 # 用户组归属 ioprio rt 4 # io调度优先级 # 当子进程被创建的时候，将子进程的pid写入到给定的文件中,cgroup/cpuset用法 writepid /dev/cpuset/foreground/tasks /dev/stune/foreground/tasks onrestart restart audio-hal-2-0 # audioserver重启会重启hal 我们看到Android 8.0当重启audioserver时，会重启audio-hal-2-0，这个服务是audio hal的服务，在android 8.0中，framework native进程与hal分离，hal不在和framework native处于同一个进程，而是独立进程，进程间通过binder通信。先不讲HAL binder化，我们先看看audioserver中包含哪几个服务。123456789101112131415161718192021222324252627282930313233int main(int argc __unused, char **argv)&#123; signal(SIGPIPE, SIG_IGN); bool doLog = (bool) property_get_bool("ro.test_harness", 0); pid_t childPid; ...... if (doLog &amp;&amp; (childPid = fork()) != 0) &#123; ...... &#125; else &#123; sp&lt;ProcessState&gt; proc(ProcessState::self()); sp&lt;IServiceManager&gt; sm = defaultServiceManager(); ALOGI("ServiceManager: %p", sm.get()); AudioFlinger::instantiate(); AudioPolicyService::instantiate(); AAudioService::instantiate(); RadioService::instantiate(); SoundTriggerHwService::instantiate(); ProcessState::self()-&gt;startThreadPool();// FIXME: remove when BUG 31748996 is fixed android::hardware::ProcessState::self()-&gt;startThreadPool(); IPCThreadState::self()-&gt;joinThreadPool(); &#125;&#125; 从如上代码可以看出，audioserver中回依次执行AudioFlinger、AudioPolicyService、AAudioService、RadioService、SoundTriggerHwService的instantiate函数。通过阅读源代码，由于继承的缘故这个五个service最终会调用BinderService的instantiate函数且将自己注册到ServiceManager中，后续client端可以通过service注册时用的name从ServiceManager返回server端。12345678910111213141516171819202122232425262728template&lt;typename SERVICE&gt;class BinderService&#123;public: static status_t publish(bool allowIsolated = false) &#123; sp&lt;IServiceManager&gt; sm(defaultServiceManager()); return sm-&gt;addService( String16(SERVICE::getServiceName()), new SERVICE(), allowIsolated); &#125; static void publishAndJoinThreadPool(bool allowIsolated = false) &#123; publish(allowIsolated); joinThreadPool(); &#125; static void instantiate() &#123; publish(); &#125; static status_t shutdown() &#123; return NO_ERROR; &#125;private: static void joinThreadPool() &#123; sp&lt;ProcessState&gt; ps(ProcessState::self()); ps-&gt;startThreadPool(); ps-&gt;giveThreadPoolName(); IPCThreadState::self()-&gt;joinThreadPool(); &#125;&#125;; AudioFlinger（media.audio_flinger）：Audio系统的一个核心服务，是音频策略的执行者，负责输入输出流设备的管理及音频流数据的处理传输。 AudioPolicyService（media.audio_policy）：音频策略的制定者，负责音频设备切换的策略抉择、音量调节策略等。 AAudioService（media.aaudio）：这是Android 8.0加入角色，是OpenSL ES的另外一种选择，需要低延迟的高性能音频应用的另外一种选择。 RadioService（media.radio）：与FM相关的一个服务。 SoundTriggerHwService（media.sound_trigger_hw）：Android语音识别的native服务。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub搭建个人的博客]]></title>
    <url>%2F2017%2F10%2F30%2FGitHub%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[最近突然间发现，自己过去看过的东西，没过多久就忘得一干二净，每当要用时，又得从头来一遍，真是好记性不如烂笔头，所以有了写笔记的想法，GitHub上可以方便记录自己一切想记录的，于是就在GitHub上开始写笔记，希望自己不要把知识忘得太快。本文记录在Windows环境下使用Hexo搭建GitHub博客的过程。 安装Node.js在nodejs官网下载对应的版本安装下载地址：https://nodejs.org/en/download 安装Git下载地址：https://git-for-windows.github.io 创建GitHub账户进入GitHub主页https://github.com/，依次输入用户名、邮箱、密码，然后点击注册，按默认点击“Finish sign up”。然后进行邮箱验证。 创建GitHub仓库点击“New repository”，新建一个仓库，仓库名为“[yourname].github.io”，这样https://[yourname].github.io 就是你的博客地址了。默认这仓库只有master分支，新建一个hexo分支。 配置Hexo接下来的命令都在Git Bash中执行。 在自己喜欢的位置新建一个blog文件夹，在这个文件夹下打开Git Bash，因为npm是国外服务器，可能执行比较慢，可以使用淘宝镜像，命令如下： $ npm install -g cnpm --registry=https://registry.npm.taobao.org 执行成功后使用淘宝NPM安装Hexo $ cnpm install -g hexo-cli $ cnmp install hexo --save $ hexo -v hexo: 3.4.0 hexo-cli: 1.0.4 os: Windows_NT 6.1.7600 win32 ia32 http_parser: 2.7.0 node: 8.7.0 v8: 6.1.534.42 uv: 1.15.0 zlib: 1.2.11 ares: 1.10.1-DEV modules: 57 nghttp2: 1.25.0 openssl: 1.0.2l icu: 59.1 unicode: 9.0 cldr: 31.0.1 tz: 2017b 到这里hexo已经安装好了 配置ssh keyssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 在C:\Users\yourname\.ssh下会得到密钥id_rsa和id_rsa.pub，用nodepad++打开id_rsa.pub复制全文，打开https://github.com/settings/ssh，Add SSH key，粘贴进去保存。 测试是否配置成功 $ ssh -T git@github.com Hi [yourname]! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 配置git信息$ git config --global user.name &quot;你的用户名&quot; $ git config --global user.email &quot;你的邮箱&quot; 使用Hexo管理博客初始化博客$ hexo init &lt;nodejs-hexo&gt; //初始化nodejs-hexo（文件夹名随意） $ git clone -b hexo https://github.com/[yourname]/[yourname].github.io 将[yourname].github.io文件夹下的.git文件夹拷贝到nodejs-hexo文件夹。 $ cnpm install //安装生成器 $ hexo server //运行（Ctrl + C停止运行） 在浏览器输入localhost:4000，这样就可以在本地看到博客了。 配置博客_config.yml中配置基本信息 title: #博客标题 subtitle: #博客副标题 description: #博客描述 author: #博客作者 language: zh-Hans timezone: Asia/Shanghai _config.yml中配置主题 theme: next _config.yml中配置部署 deploy: type: git repo: https://github.com/[yourname]/[yourname].github.io branch: master 注意：这里的设置冒号后面必须有空格 发布博客$ hexo new &quot;博客名&quot; //增加新文章 $ cnpm install hexo-deployer-git --save //安装hexo git插件 $ git add . $ git commit -m &quot;message&quot; $ git push origin hexo $ hexo generate //生成静态文件 $ hexo deploy //部署 换PC管理博客$ git clone -b hexo https://github.com/[yourname]/[yourname].github.io 在[yourname].github.io中从新安装hexo，就可以写博客及发布博客了。 参考Next主题配置参考：http://theme-next.iissnan.com/theme-settings.html]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
