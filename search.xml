<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[AudioPolicyService启动过程]]></title>
    <url>%2F2017%2F11%2F10%2FAudioPolicyService%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[AudioPolicyService在Audio系统另一个重要的服务，是音频策略的制定者，负责音频设备切换的策略抉择、音量调节策略等。本文基于Android 8.0的代码，记录了AudioPolicyService启动的过程，介绍了其中几个比较关键的点，希望以后自己看到此文能快速回想起AudioPolicyService的启动过程。其代码位于frameworks/av/services/audiopolicy。 audiopolicy的代码结构 service目录是AudioPolicyService、AudioPolicyClient、AudioCommandThread及AudioPolicyEffects的定义及实现。 managerdefault目录提供AudioPolicyManager的基本实现。 manager目录中是一个工厂类可以根据需要生产所需的AudioPolicyManager，一般各个厂商都会自己实现自己的AudioPolicyManager。 engine目录定义了AudioPolicyManagerInterface和AudioPolicyManagerObserver接口，AudioPolicyManagerInterface由Policy Engine实现，AudioPolicyManagerObserver这个观察者由AudioPolicyManager实现，以供Engine访问。 engineconfigure和enginedefault目录是Policy Engine的两种实现，可以根据需要选择其中一种。 config目录存放audio policy及音量曲线的config文件。 common目录下定义公共代码。audio_policy.conf是旧版本的audio policy config文件。 AudioPolicyInterface.h定义了AudioPolicyInterface和AudioPolicyClientInterface接口，AudioPolicyInterface由AuidoPolicyManager实现，特定平台AuidoPolicyManager通过AudioPolicyClientInterface接口的实现者AudioPolicyClient控制音频的输入输出。AudioPolicyService初始化从Android 8.0的code发现，基本流程还是和之前一样，分别创建了ApmTone、ApmAudio、ApmOutput三个AudioCommandThread线程，分别用于播放tone音、执行audio命令和执行输出命令，创建AudioPolicyClient，创建AudioPolicyManager以及创建AudioPolicyEffects。但已经完全移除了对旧版本的AUDIO_POLICY_HARDWARE_MODULE_ID的支持（不再加载audio_policy.default.so库得到audio_policy_module模块），完全使用新模式。12345678910111213141516171819202122232425262728AudioPolicyService::AudioPolicyService() : BnAudioPolicyService(), mpAudioPolicyDev(NULL), mpAudioPolicy(NULL), mAudioPolicyManager(NULL), mAudioPolicyClient(NULL), mPhoneState(AUDIO_MODE_INVALID)&#123;&#125;void AudioPolicyService::onFirstRef()&#123; &#123; Mutex::Autolock _l(mLock); // start tone playback thread mTonePlaybackThread = new AudioCommandThread(String8("ApmTone"), this); // start audio commands thread mAudioCommandThread = new AudioCommandThread(String8("ApmAudio"), this); // start output activity command thread mOutputCommandThread = new AudioCommandThread(String8("ApmOutput"), this); mAudioPolicyClient = new AudioPolicyClient(this); mAudioPolicyManager = createAudioPolicyManager(mAudioPolicyClient); &#125; // load audio processing modules sp&lt;AudioPolicyEffects&gt;audioPolicyEffects = new AudioPolicyEffects(); &#123; Mutex::Autolock _l(mLock); mAudioPolicyEffects = audioPolicyEffects; &#125;&#125; 这些类之间的大致关系如下（AudioPolicyClient和AudioCommandThread都为AudioPolicyService的内部类）：AudioPolicyService的初始化大致分为3步：1.创建三个AudioCommandThread（mTonePlaybackThread，mAudioCommandThread和mOutputCommandThread）2.初始化AudioPolicyManager 2.1 加载并解析audio_policy_configuration.xml 2.2 加载对应的HW module 2.3 初始化Policy Engine 2.4 打开输入输出 2.5 确保所有可用输入输出设备和默认输出设备真正可用3.初始化AudioPolicyEffects AudioCommandThread线程AudioCommandThread采用异步方式来执行audio command，当需要执行上表中的命令时，首先将命令投递到AudioCommandThread的mAudioCommands命令向量表中，然后通过mWaitWorkCV.signal()唤醒AudioCommandThread线程，被唤醒的AudioCommandThread线程执行完command后，又通过mWaitWorkCV.waitRelative(mLock, waitTime)睡眠等待命令到来。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879void AudioPolicyService::AudioCommandThread::onFirstRef()&#123; run(mName.string(), ANDROID_PRIORITY_AUDIO);&#125;status_t AudioPolicyService::AudioCommandThread::volumeCommand(audio_stream_type_t stream, float volume, audio_io_handle_t output, int delayMs)&#123; sp&lt;AudioCommand&gt; command = new AudioCommand(); command-&gt;mCommand = SET_VOLUME; sp&lt;VolumeData&gt; data = new VolumeData(); data-&gt;mStream = stream; data-&gt;mVolume = volume; data-&gt;mIO = output; command-&gt;mParam = data; command-&gt;mWaitStatus = true; return sendCommand(command, delayMs);&#125;bool AudioPolicyService::AudioCommandThread::threadLoop()&#123; nsecs_t waitTime = -1; mLock.lock(); while (!exitPending()) &#123; sp&lt;AudioPolicyService&gt; svc; while (!mAudioCommands.isEmpty() &amp;&amp; !exitPending()) &#123; nsecs_t curTime = systemTime(); // commands are sorted by increasing time stamp: execute them from index 0 and up if (mAudioCommands[0]-&gt;mTime &lt;= curTime) &#123; sp&lt;AudioCommand&gt; command = mAudioCommands[0]; mAudioCommands.removeAt(0); mLastCommand = command; switch (command-&gt;mCommand) &#123; ...... case SET_VOLUME: &#123; VolumeData *data = (VolumeData *)command-&gt;mParam.get(); ALOGV("AudioCommandThread() processing set volume stream %d, \ volume %f, output %d", data-&gt;mStream, data-&gt;mVolume, data-&gt;mIO); command-&gt;mStatus = AudioSystem::setStreamVolume(data-&gt;mStream, data-&gt;mVolume, data-&gt;mIO); &#125;break; ...... &#125; ..... &#125; else &#123; waitTime = mAudioCommands[0]-&gt;mTime - curTime; break; &#125; &#125; ...... // At this stage we have either an empty command queue or the first command in the queue // has a finite delay. So unless we are exiting it is safe to wait. if (!exitPending()) &#123; ALOGV("AudioCommandThread() going to sleep"); if (waitTime == -1) &#123; mWaitWorkCV.wait(mLock); &#125; else &#123; mWaitWorkCV.waitRelative(mLock, waitTime); &#125; &#125; &#125; ...... mLock.unlock(); return false;&#125; AudioCommandThread是AudioPolicyService的内部类，AudioCommandThread在内部又定义了AudioCommand及AudioCommandData关系如下。 AudioPolicyManager初始化12345678910111213141516171819202122232425262728293031323334AudioPolicyManager::AudioPolicyManager(AudioPolicyClientInterface *clientInterface) : mLimitRingtoneVolume(false), mLastVoiceVolume(-1.0f), mA2dpSuspended(false), mAudioPortGeneration(1), mBeaconMuteRefCount(0), mBeaconPlayingRefCount(0), mBeaconMuted(false), mTtsOutputAvailable(false), mMasterMono(false), mMusicEffectOutput(AUDIO_IO_HANDLE_NONE), mHasComputedSoundTriggerSupportsConcurrentCapture(false)&#123; mUidCached = getuid(); mpClientInterface = clientInterface; ...... // audio policy config加载 // 初始化Policy Engine for (size_t i = 0; i &lt; mHwModules.size(); i++) &#123; // 加载所有的HW module ...... // 打开音频输入输出 &#125; // 确保所有可用输入输出设备真正可用 ...... // 确保默认输出设备真正可用 ALOGE_IF((mPrimaryOutput == 0), "Failed to open primary output"); updateDevicesAndOutputs();&#125; audio policy config加载进入AudioPolicyManager构造函数，会首先加载audio policy config文件，对于旧版本使用audio_policy.conf，在代码中定义音量曲线，对于新版本使用audio_policy_configuration.xml。对于Android 8.0使用新版本，这个文件一般会位于/odm/etc或/vendor/etc，同时解析音量曲线xml（audio_policy_volumes.xml和default_volume_tables.xml）,比起之前的硬编码音量曲线，灵活性更好。1234567891011121314151617181920#ifdef USE_XML_AUDIO_POLICY_CONF mVolumeCurves = new VolumeCurvesCollection(); AudioPolicyConfig config(mHwModules, mAvailableOutputDevices, mAvailableInputDevices, mDefaultOutputDevice, speakerDrcEnabled, static_cast&lt;VolumeCurvesCollection *&gt;(mVolumeCurves)); if (deserializeAudioPolicyXmlConfig(config) != NO_ERROR) &#123;#else mVolumeCurves = new StreamDescriptorCollection(); AudioPolicyConfig config(mHwModules, mAvailableOutputDevices, mAvailableInputDevices, mDefaultOutputDevice, speakerDrcEnabled); if ((ConfigParsingUtils::loadConfig(AUDIO_POLICY_VENDOR_CONFIG_FILE, config) != NO_ERROR) &amp;&amp; (ConfigParsingUtils::loadConfig(AUDIO_POLICY_CONFIG_FILE, config) != NO_ERROR)) &#123;#endif ALOGE("could not load audio policy configuration file, setting defaults"); config.setDefault(); &#125; // must be done after reading the policy (since conditionned by Speaker Drc Enabling) // xml模式时这里是一个空函数无实现 mVolumeCurves-&gt;initializeVolumeCurves(speakerDrcEnabled); 当执行完deserializeAudioPolicyXmlConfig，会得到mHwModules对应各个Audio HAL模块、mAvailableOutputDevices可用的输出设备、mAvailableInputDevices可用的输入设备、mDefaultOutputDevice默认输出设备、mVolumeCurves音量曲线及speakerDrcEnabled。 audio_policy_configuration.xml同时定义了多个audio接口(HwModules)，每一个audio接口包含若干routes（通路）、devicesPorts（设备）和mixPorts（音频流），而每个mixPorts又包含多个input和output流，每个input和output流又同时支持多种输入输出模式，每种输入输出模式又支持若干种设备。mixPorts：listing all output and input streams exposed by the audio HAL.routes：list of possible connections between input and output devices or between stream and devices.devicePorts：a list of device descriptors for all input and output devices accessible via this module.This contains both permanently attached devices and removable devices.每个stream type会分为四种device category：DEVICE_CATEGORY_HEADSET，DEVICE_CATEGORY_SPEAKER，DEVICE_CATEGORY_EARPIECE及DEVICE_CATEGORY_EXT_MEDIA来定义音量曲线，定义的形式如下，一样是分段定义，在每一段中定义不同的衰减值以控制音量的大小。It contains a list of points of this curve expressing the attenuation in Millibels for a given volume index from 0 to 100.123456&lt;volume stream="AUDIO_STREAM_VOICE_CALL" deviceCategory="DEVICE_CATEGORY_HEADSET"&gt; &lt;point&gt;0,-4200&lt;/point&gt; &lt;point&gt;33,-2800&lt;/point&gt; &lt;point&gt;66,-1400&lt;/point&gt; &lt;point&gt;100,0&lt;/point&gt;&lt;/volume&gt; 初始化Policy Engine这里也算一个观察者模式吧，EngineInstance是单例模式，通过EngineInstance创建AudioPolicyManagerInterface，从而创建Policy Engine，然后设置观察者。12345678910111213141516// Once policy config has been parsed, retrieve an instance of the engine and initialize it. audio_policy::EngineInstance *engineInstance = audio_policy::EngineInstance::getInstance(); if (!engineInstance) &#123; ALOGE("%s: Could not get an instance of policy engine", __FUNCTION__); return; &#125; // Retrieve the Policy Manager Interface mEngine = engineInstance-&gt;queryInterface&lt;AudioPolicyManagerInterface&gt;(); if (mEngine == NULL) &#123; ALOGE("%s: Failed to get Policy Engine Interface", __FUNCTION__); return; &#125; mEngine-&gt;setObserver(this); status_t status = mEngine-&gt;initCheck(); (void) status; ALOG_ASSERT(status == NO_ERROR, "Policy engine not initialized(err=%d)", status); 其大致关系如下。 加载HW Module根据audio policy config加载的HwModule真正加载HAL层的HW module。123456789101112// mAvailableOutputDevices and mAvailableInputDevices now contain all attached devices// open all output streams needed to access attached devicesaudio_devices_t outputDeviceTypes = mAvailableOutputDevices.types();audio_devices_t inputDeviceTypes = mAvailableInputDevices.types() &amp; ~AUDIO_DEVICE_BIT_IN;for (size_t i = 0; i &lt; mHwModules.size(); i++) &#123; mHwModules[i]-&gt;mHandle = mpClientInterface-&gt;loadHwModule(mHwModules[i]-&gt;getName()); if (mHwModules[i]-&gt;mHandle == 0) &#123; continue; &#125; ......&#125; 从如上代码看出，会执行mpClientInterface-&gt;loadHwModule，即调用AudioPolicyClient的loadHwModule函数，又会转到AudioFlinger的loadHwModule。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859audio_module_handle_t AudioPolicyService::AudioPolicyClient::loadHwModule(const char *name)&#123; sp&lt;IAudioFlinger&gt; af = AudioSystem::get_audio_flinger(); if (af == 0) &#123; ALOGW("%s: could not get AudioFlinger", __func__); return AUDIO_MODULE_HANDLE_NONE; &#125; return af-&gt;loadHwModule(name);&#125;audio_module_handle_t AudioFlinger::loadHwModule(const char *name)&#123; if (name == NULL) &#123; return AUDIO_MODULE_HANDLE_NONE; &#125; if (!settingsAllowed()) &#123; return AUDIO_MODULE_HANDLE_NONE; &#125; Mutex::Autolock _l(mLock); return loadHwModule_l(name);&#125;// loadHwModule_l() must be called with AudioFlinger::mLock heldaudio_module_handle_t AudioFlinger::loadHwModule_l(const char *name)&#123; for (size_t i = 0; i &lt; mAudioHwDevs.size(); i++) &#123; if (strncmp(mAudioHwDevs.valueAt(i)-&gt;moduleName(), name, strlen(name)) == 0) &#123; ALOGW("loadHwModule() module %s already loaded", name); return mAudioHwDevs.keyAt(i); &#125; &#125; sp&lt;DeviceHalInterface&gt; dev; int rc = mDevicesFactoryHal-&gt;openDevice(name, &amp;dev); if (rc) &#123; ALOGE("loadHwModule() error %d loading module %s", rc, name); return AUDIO_MODULE_HANDLE_NONE; &#125; ...... // Check and cache this HAL's level of support for master mute and master // volume. If this is the first HAL opened, and it supports the get // methods, use the initial values provided by the HAL as the current // master mute and volume settings. ...... audio_module_handle_t handle = (audio_module_handle_t) nextUniqueId(AUDIO_UNIQUE_ID_USE_MODULE); mAudioHwDevs.add(handle, new AudioHwDevice(handle, name, dev, flags)); ALOGI("loadHwModule() Loaded %s audio interface, handle %d", name, handle); return handle;&#125; mDevicesFactoryHal-&gt;openDevice(name, &amp;dev),从前面AudioFlinger的启动，我们知道mDevicesFactoryHal是HAL进程的客户端，对于Android 8.0加载HAL so文件已经移到HAL进程中，不再与audioserver处于同一个进程中。在AudioFlinger中使用AudioHwDevice代表HW Module，AudioHwDevice会封装audio_module_handle_t和DeviceHalInterface，并以audio_module_handle_t为key将其保存在AudioFlinger的mAudioHwDevs中，以供后续查询。到这里就加载系统的音频接口就加载完了，我们大致可以得出如下结果。 打开音频输出这里的输出，即mixPorts中outputs，也就是mHwModules中所有OutputProfile（IOProfile），代表了音频输出流。所以会遍历mHwModules中所有OutputProfile，然后SwAudioOutputDescriptor来描述每一个output，最终保存在以audio_io_handle_t为key的mOutputs中，以供后续查询。不过这里会除了AUDIO_OUTPUT_FLAG_DIRECT，AUDIO_OUTPUT_FLAG_DIRECT的output会在使用的时候打开，不会预先open。在打开输出设备后还会标记可用输出设备的可用情况，以备后续确认可用输出设备真正可用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// open all output streams needed to access attached devices// except for direct output streams that are only opened when they are actually// required by an app.// This also validates mAvailableOutputDevices listfor (size_t j = 0; j &lt; mHwModules[i]-&gt;mOutputProfiles.size(); j++)&#123; const sp&lt;IOProfile&gt; outProfile = mHwModules[i]-&gt;mOutputProfiles[j]; if (!outProfile-&gt;hasSupportedDevices()) &#123; continue; &#125; if ((outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_TTS) != 0) &#123; mTtsOutputAvailable = true; &#125; if ((outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_DIRECT) != 0) &#123; continue; &#125; audio_devices_t profileType = outProfile-&gt;getSupportedDevicesType(); if ((profileType &amp; mDefaultOutputDevice-&gt;type()) != AUDIO_DEVICE_NONE) &#123; profileType = mDefaultOutputDevice-&gt;type(); &#125; else &#123; // chose first device present in profile's SupportedDevices also part of // outputDeviceTypes profileType = outProfile-&gt;getSupportedDeviceForType(outputDeviceTypes); &#125; if ((profileType &amp; outputDeviceTypes) == 0) &#123; continue; &#125; sp&lt;SwAudioOutputDescriptor&gt; outputDesc = new SwAudioOutputDescriptor(outProfile, mpClientInterface); const DeviceVector &amp;supportedDevices = outProfile-&gt;getSupportedDevices(); const DeviceVector &amp;devicesForType = supportedDevices.getDevicesFromType(profileType); String8 address = devicesForType.size() &gt; 0 ? devicesForType.itemAt(0)-&gt;mAddress : String8(""); outputDesc-&gt;mDevice = profileType; audio_config_t config = AUDIO_CONFIG_INITIALIZER; config.sample_rate = outputDesc-&gt;mSamplingRate; config.channel_mask = outputDesc-&gt;mChannelMask; config.format = outputDesc-&gt;mFormat; audio_io_handle_t output = AUDIO_IO_HANDLE_NONE; status_t status = mpClientInterface-&gt;openOutput(outProfile-&gt;getModuleHandle(), &amp;output, &amp;config, &amp;outputDesc-&gt;mDevice, address, &amp;outputDesc-&gt;mLatency, outputDesc-&gt;mFlags); if (status != NO_ERROR) &#123; ...... &#125; else &#123; outputDesc-&gt;mSamplingRate = config.sample_rate; outputDesc-&gt;mChannelMask = config.channel_mask; outputDesc-&gt;mFormat = config.format; for (size_t k = 0; k &lt; supportedDevices.size(); k++) &#123; ssize_t index = mAvailableOutputDevices.indexOf(supportedDevices[k]); // give a valid ID to an attached device once confirmed it is reachable if (index &gt;= 0 &amp;&amp; !mAvailableOutputDevices[index]-&gt;isAttached()) &#123; mAvailableOutputDevices[index]-&gt;attach(mHwModules[i]); &#125; &#125; if (mPrimaryOutput == 0 &amp;&amp; outProfile-&gt;getFlags() &amp; AUDIO_OUTPUT_FLAG_PRIMARY) &#123; mPrimaryOutput = outputDesc; &#125; addOutput(output, outputDesc); setOutputDevice(outputDesc, outputDesc-&gt;mDevice, true, 0, NULL, address.string()); &#125;&#125; 我们看到会使用到mpClientInterface打开输出，即调用AudioPolicyClient的openOutput，即调用AudioFlinger的openOutput及openOutput_l。首先调用findSuitableHwDev_l查询合适的AudioHwDevice，即通过audio_module_handle_t在之前加载的mAudioHwDevs中去除对应的AudioHwDevice，调用AudioHwDevice的openOutputStream得到AudioStreamOut，然后根据output flag创建相应的Thread，最后以audio_io_handle_t为key将Thread保存在mPlaybackThreads和mMmapThreads。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798sp&lt;AudioFlinger::ThreadBase&gt; AudioFlinger::openOutput_l(audio_module_handle_t module, audio_io_handle_t *output, audio_config_t *config, audio_devices_t devices, const String8&amp; address, audio_output_flags_t flags)&#123; AudioHwDevice *outHwDev = findSuitableHwDev_l(module, devices); if (outHwDev == NULL) &#123; return 0; &#125; if (*output == AUDIO_IO_HANDLE_NONE) &#123; *output = nextUniqueId(AUDIO_UNIQUE_ID_USE_OUTPUT); &#125; else &#123; return 0; &#125; mHardwareStatus = AUDIO_HW_OUTPUT_OPEN; // FOR TESTING ONLY: ...... AudioStreamOut *outputStream = NULL; status_t status = outHwDev-&gt;openOutputStream( &amp;outputStream, *output, devices, flags, config, address.string()); mHardwareStatus = AUDIO_HW_IDLE; if (status == NO_ERROR) &#123; if (flags &amp; AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) &#123; sp&lt;MmapPlaybackThread&gt; thread = new MmapPlaybackThread(this, *output, outHwDev, outputStream, devices, AUDIO_DEVICE_NONE, mSystemReady); mMmapThreads.add(*output, thread); ALOGV("openOutput_l() created mmap playback thread: ID %d thread %p", *output, thread.get()); return thread; &#125; else &#123; sp&lt;PlaybackThread&gt; thread; if (flags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) &#123; thread = new OffloadThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created offload output: ID %d thread %p", *output, thread.get()); &#125; else if ((flags &amp; AUDIO_OUTPUT_FLAG_DIRECT) || !isValidPcmSinkFormat(config-&gt;format) || !isValidPcmSinkChannelMask(config-&gt;channel_mask)) &#123; thread = new DirectOutputThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created direct output: ID %d thread %p", *output, thread.get()); &#125; else &#123; thread = new MixerThread(this, outputStream, *output, devices, mSystemReady); ALOGV("openOutput_l() created mixer output: ID %d thread %p", *output, thread.get()); &#125; mPlaybackThreads.add(*output, thread); return thread; &#125; &#125; return 0;&#125;status_t AudioFlinger::openOutput(audio_module_handle_t module, audio_io_handle_t *output, audio_config_t *config, audio_devices_t *devices, const String8&amp; address, uint32_t *latencyMs, audio_output_flags_t flags)&#123; if (devices == NULL || *devices == AUDIO_DEVICE_NONE) &#123; return BAD_VALUE; &#125; Mutex::Autolock _l(mLock); sp&lt;ThreadBase&gt; thread = openOutput_l(module, output, config, *devices, address, flags); if (thread != 0) &#123; if ((flags &amp; AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) == 0) &#123; PlaybackThread *playbackThread = (PlaybackThread *)thread.get(); *latencyMs = playbackThread-&gt;latency(); // notify client processes of the new output creation playbackThread-&gt;ioConfigChanged(AUDIO_OUTPUT_OPENED); // the first primary output opened designates the primary hw device if ((mPrimaryHardwareDev == NULL) &amp;&amp; (flags &amp; AUDIO_OUTPUT_FLAG_PRIMARY)) &#123; ALOGI("Using module %d as the primary audio interface", module); mPrimaryHardwareDev = playbackThread-&gt;getOutput()-&gt;audioHwDev; AutoMutex lock(mHardwareLock); mHardwareStatus = AUDIO_HW_SET_MODE; mPrimaryHardwareDev-&gt;hwDevice()-&gt;setMode(mMode); mHardwareStatus = AUDIO_HW_IDLE; &#125; &#125; else &#123; MmapThread *mmapThread = (MmapThread *)thread.get(); mmapThread-&gt;ioConfigChanged(AUDIO_OUTPUT_OPENED); &#125; return NO_ERROR; &#125; return NO_INIT;&#125; 我们可以看到在AudioPolicyManager中有mOutputs以audio_io_handle_t为key保存SwAudioOutputDescriptor，而在AudioFlinger中mPlaybackThreads和mMmapThreads以audio_io_handle_t保存线程，所以我们可以得出如下关系图。 打开音频输入打开音频输入和打开音频输出很类似，只是将SwAudioOutputDescriptor、PlaybackThread及AudioStreamOut换成了AudioInputDescriptor、RecordThread及AudioStreamIn，这里就一笔带过。 确保可用输入输出和默认输出真正可用无其他。主要是移除不可达设备。1234567891011121314151617181920212223242526272829303132333435363738// make sure all attached devices have been allocated a unique ID// 确保所有可用输出设备真正可用for (size_t i = 0; i &lt; mAvailableOutputDevices.size();) &#123; if (!mAvailableOutputDevices[i]-&gt;isAttached()) &#123; ALOGW("Output device %08x unreachable", mAvailableOutputDevices[i]-&gt;type()); mAvailableOutputDevices.remove(mAvailableOutputDevices[i]); continue; &#125; // The device is now validated and can be appended to the available // devices of the engine // 目前不做任何处理 mEngine-&gt;setDeviceConnectionState(mAvailableOutputDevices[i], AUDIO_POLICY_DEVICE_STATE_AVAILABLE); i++;&#125;// 确保所有可用输入设备真正可用for (size_t i = 0; i &lt; mAvailableInputDevices.size();) &#123; if (!mAvailableInputDevices[i]-&gt;isAttached()) &#123; ALOGW("Input device %08x unreachable", mAvailableInputDevices[i]-&gt;type()); mAvailableInputDevices.remove(mAvailableInputDevices[i]); continue; &#125; // The device is now validated and can be appended to the available devices of the engine // 目前不做任何处理 mEngine-&gt;setDeviceConnectionState(mAvailableInputDevices[i], AUDIO_POLICY_DEVICE_STATE_AVAILABLE); i++;&#125;// make sure default device is reachable// 确保默认输出设备真正可用if (mDefaultOutputDevice == 0 || mAvailableOutputDevices.indexOf(mDefaultOutputDevice) &lt; 0) &#123; ALOGE("Default device %08x is unreachable", mDefaultOutputDevice-&gt;type());&#125;ALOGE_IF((mPrimaryOutput == 0), "Failed to open primary output");updateDevicesAndOutputs(); AudioPolicyEffects初始化对于音效策略，类似会先加载audio_effects.conf，这个文件可能位于system/etc/或者vendor/etc/。123456789AudioPolicyEffects::AudioPolicyEffects()&#123; // load automatic audio effect modules if (access(AUDIO_EFFECT_VENDOR_CONFIG_FILE, R_OK) == 0) &#123; loadAudioEffectConfig(AUDIO_EFFECT_VENDOR_CONFIG_FILE); &#125; else if (access(AUDIO_EFFECT_DEFAULT_CONFIG_FILE, R_OK) == 0) &#123; loadAudioEffectConfig(AUDIO_EFFECT_DEFAULT_CONFIG_FILE); &#125;&#125; 这个文件的格式如下。123456789101112131415161718192021# List of effect libraries to load. Each library element must contain a "path" element# giving the full path of the library .so file.# libraries &#123;# &lt;lib name&gt; &#123;# path &lt;lib path&gt;# &#125;# &#125;# list of effects to load. Each effect element must contain a "library" and a "uuid" element.# The value of the "library" element must correspond to the name of one library element in the# "libraries" element.# The name of the effect element is indicative, only the value of the "uuid" element# designates the effect.# The uuid is the implementation specific UUID as specified by the effect vendor. This is not the# generic effect type UUID.# effects &#123;# &lt;fx name&gt; &#123;# library &lt;lib name&gt;# uuid &lt;effect uuid&gt;# &#125;# ...# &#125; 到这里AudioPolicyService的启动流程已经完结，且篇幅已经挺长，其他的知识点，学习到时再补上。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AudioFlinger启动过程]]></title>
    <url>%2F2017%2F11%2F09%2FAudioFlinger%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[AudioFlinger以media.audio_flinger为名注册到ServiceManager，是Android Audio系统的一个核心服务，是音频策略的执行者，负责输入输出流设备的管理及音频流数据的处理传输。本文以Android 8.0的代码为基础，记录了其启动过程以及AudioFlinger主要类的关系。其代码位于frameworks/av/services/audioflinger。 AudioFlinger的启动过程Android 8.0中与7.0相比，在初始化过程中，主要是实例化了mDevicesFactoryHal和mEffectsFactoryHal，作为HAL进程的客户端与HAL进程交互。12345678910111213141516171819202122232425AudioFlinger::AudioFlinger() //变量初始化 : BnAudioFlinger(), mMediaLogNotifier(new AudioFlinger::MediaLogNotifier()), mPrimaryHardwareDev(NULL), mAudioHwDevs(NULL), mHardwareStatus(AUDIO_HW_IDLE), mMasterVolume(1.0f), mMasterMute(false), // mNextUniqueId(AUDIO_UNIQUE_ID_USE_MAX), mMode(AUDIO_MODE_INVALID), mBtNrecIsOff(false), mIsLowRamDevice(true), mIsDeviceTypeKnown(false), mGlobalEffectEnableTime(0), mSystemReady(false)&#123; ...... mDevicesFactoryHal = DevicesFactoryHalInterface::create(); mEffectsFactoryHal = EffectsFactoryHalInterface::create(); ......&#125; 这里我们主要看一下DevicesFactoryHalInterface关系图。EffectsFactoryHalInterface也是类似的情况。阅读每个类的代码实现，我们发现只有DevicesFactoryHalHybrid实现了DevicesFactoryHalInterface接口的create()函数，所以这里会创建DevicesFactoryHalHybrid实例，而DevicesFactoryHalHybrid会创建DevicesFactoryHalLocal和DevicesFactoryHalHidl实例。DevicesFactoryHalLocal用于直接加载HAL的lib，是为了兼容8.0之前的版本，而DevicesFactoryHalHidl通过binder通信从hwservicemanager中返回IDevicesFactory实例，通过IDevicesFactory的openDevice函数返回具体的Device，并且用DeviceHalHidl封装返回的Device，这里不再会直接加载HAL的lib，后续和HAL的通信完全通过IDevicesFactory接口，具体在AudioPolicyService加载HW module时会更清楚明白。 第一次初始化还会执行onFirstRef()，创建PatchPanel实例且将AudioFlinger实例传入PatchPanel，设置Audio Mode为AUDIO_MODE_NORMAL,并将自己保存在全局变量gAudioFlinger。123456789101112void AudioFlinger::onFirstRef()&#123; Mutex::Autolock _l(mLock); ...... mPatchPanel = new PatchPanel(this); mMode = AUDIO_MODE_NORMAL; gAudioFlinger = this;&#125; Mutex是互斥类，用于多线程访问同一个资源的时候，保证一次只有一个线程能访问该资源。它的工作原理是某一个线程要访问公共资源的时候先锁定这个Mutex，完成操作之后对Mutex解锁，在此期间如果有其它的线程也要访问公共资源，它就先要去锁Mutex，当它发现Mutex已经被锁住了，那么这个线程就是阻塞在那儿。等Mutex解锁之后所有阻塞在Mutex的线程都会醒来，只有第一个醒来的会抢到Mutex，其它没有抢到的发现自己晚了一步，只能继续阻塞在那儿，等待下次机会。Mutex源码位置/system/core/libutils/include/utils。 为了简化一般的Mutex操作，在class Mutex中定义了一个内部类Autolock，它利用{}作用域实现自动解锁，看一下它的构造函数就知道了。12345678class Autolock &#123; public: inline explicit Autolock(Mutex&amp; mutex) : mLock(mutex) &#123; mLock.lock(); &#125; inline explicit Autolock(Mutex* mutex) : mLock(*mutex) &#123; mLock.lock(); &#125; inline ~Autolock() &#123; mLock.unlock(); &#125; private: Mutex&amp; mLock;&#125;; 我们知道在{}中创建的变量，变开这个大括号时就要销毁，于是就自动调用析构函数了。 AudioFlinger中放音录音线程AudioFlinger作为音频的核心服务，主要责任是负责放音与录音，下面我们可以大致看看放音与录音线程的关系，在AudioPolicyServic启动过程中我们会看到这些线程的创建。 ThreadBase：ThreadBase以Thread为基类，而又是PlaybackThread、RecordThread和MmapThread的基类。 RecordThread：音频录音线程，负责音频的录音，没有子类。 PlaybackThread：代表放音线程，有两个直接子类MixerThread和DirectOutputThread。 MixerThread：混音放音线程，有子类DuplicatingThread，负责处理标识为AUDIO_OUTPUT_FLAG_PRIMARY、AUDIO_OUTPUT_FLAG_FAST、AUDIO_OUTPUT_FLAG_DEEP_BUFFER的音频流，MixerThread 可以把多个音轨的数据混音后再输出。 DirectOutputThread：直接输出放音线程，有子类OffloadThread，负责处理标识为AUDIO_OUTPUT_FLAG_DIRECT的音频流，这种音频流数据不需要软件混音，直接输出到音频设备即可。 DuplicatingThread：复制输出放音线程，负责复制音频流数据到其他输出设备，使用场景如主声卡设备、蓝牙耳机设备、USB声卡设备同时输出。 OffloadThread：硬解回放线程，负责处理标识为AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD的音频流，这种音频流未经软件解码的（一般是MP3、AAC等格式的数据），需要输出到硬件解码器，由硬件解码器解码成PCM 数据。 MmapThread：这个线程是Android 8.0新加入的，用于低延迟的放音与录音，与AAudio有关系，有MmapPlaybackThread和MmapCaptureThread两个子类。 MmapPlaybackThread：MMAP放音线程，负责处理标识为AUDIO_OUTPUT_FLAG_MMAP_NOIRQ的音频流。 MmapcaptureThread：MMAP录音线程，负责处理标识为AUDIO_INPUT_FLAG_MMAP_NOIRQ的音频流。AudioFlinger中TracksTrack：音轨，是AudioFlinger中另一个重要的将角色，下面我们可以看看其关系。对于播放对应Track，OutputTrack，TrackHandle及BnAudioTrack，TrackHandle和BnAudioTrack主要用于和Client端Binder通信，真正代表输出音轨的为Track。同样对应录音音轨的是RecordTrack，RecordHandle及BnAudioRecord，RecordHandle和BnAudioRecord也用于Binder通信，真正录音音轨为RecordTrack。而对于MmapTrack稍微不太样，而是定义通用接口MmapStreamInterface封装MmapThread，再封装MmapTrack，不是通过XXXHandle继承BnXXX，这也许是出于latency上的考虑。AudioFlinger中的Streams我们看到在AudioFlinger中以AudioHwDevice封装HAL的DeviceHalHidl，而DeviceHalHidl封装从HAL返回的具体的Device，这就和HAL层的so文件连接在一起，且AudioHwDevice直接或间接依赖AudioStreamOut和AudioStreanIn这样也和HAL层中stream关联上，后续打开音频输入输出以及打开输入音频流及输出音频流做好准备。具体我们可以在AudioPolicyService启动的时候看的更清楚。AudioFlinger中还有很多其他的知识点，后续学到时再慢慢补上。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Audio Server启动]]></title>
    <url>%2F2017%2F11%2F08%2FAndroid-Audio-Server%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[Android audioserver是Audio系统native的服务，也是连接Audio Framework和Audio HAL的一个纽带，其中包含了AudioFlinger、AudioPolicyService、AAudioService、RadioService、SoundTriggerHwService等服务。源代码位于frameworks/av/media/audioserver 从Android 7.0开始，Audio相关的service从mediaserver中转移到audioserver，把audio，camera及mediaplayerservice做了一个拆分，这样不会显得臃肿、职能更加独立且安全性更高。拆分之后audioserver还是一个native service，还是从init进程中启动，如下是其在audioserver.rc中的启动代码。 12345678910service audioserver /system/bin/audioserver class main # audioserver和class main行为一致 user audioserver # 用户归属，uid：AID_AUDIOSERVER # media gid needed for /dev/fm (radio) and for /data/misc/media (tee) group audio camera drmrpc inet media mediadrm net_bt \ net_bt_admin net_bw_acct oem_2901 # 用户组归属 ioprio rt 4 # io调度优先级 # 当子进程被创建的时候，将子进程的pid写入到给定的文件中,cgroup/cpuset用法 writepid /dev/cpuset/foreground/tasks /dev/stune/foreground/tasks onrestart restart audio-hal-2-0 # audioserver重启会重启hal 我们看到Android 8.0当重启audioserver时，会重启audio-hal-2-0，这个服务是audio hal的服务，在android 8.0中，framework native进程与hal分离，hal不在和framework native处于同一个进程，而是独立进程，进程间通过binder通信。先不讲HAL binder化，我们先看看audioserver中包含哪几个服务。123456789101112131415161718192021222324252627282930313233int main(int argc __unused, char **argv)&#123; signal(SIGPIPE, SIG_IGN); bool doLog = (bool) property_get_bool("ro.test_harness", 0); pid_t childPid; ...... if (doLog &amp;&amp; (childPid = fork()) != 0) &#123; ...... &#125; else &#123; sp&lt;ProcessState&gt; proc(ProcessState::self()); sp&lt;IServiceManager&gt; sm = defaultServiceManager(); ALOGI("ServiceManager: %p", sm.get()); AudioFlinger::instantiate(); AudioPolicyService::instantiate(); AAudioService::instantiate(); RadioService::instantiate(); SoundTriggerHwService::instantiate(); ProcessState::self()-&gt;startThreadPool();// FIXME: remove when BUG 31748996 is fixed android::hardware::ProcessState::self()-&gt;startThreadPool(); IPCThreadState::self()-&gt;joinThreadPool(); &#125;&#125; 从如上代码可以看出，audioserver中回依次执行AudioFlinger、AudioPolicyService、AAudioService、RadioService、SoundTriggerHwService的instantiate函数。通过阅读源代码，由于继承的缘故这个五个service最终会调用BinderService的instantiate函数且将自己注册到ServiceManager中，后续client端可以通过service注册时用的name从ServiceManager返回server端。12345678910111213141516171819202122232425262728template&lt;typename SERVICE&gt;class BinderService&#123;public: static status_t publish(bool allowIsolated = false) &#123; sp&lt;IServiceManager&gt; sm(defaultServiceManager()); return sm-&gt;addService( String16(SERVICE::getServiceName()), new SERVICE(), allowIsolated); &#125; static void publishAndJoinThreadPool(bool allowIsolated = false) &#123; publish(allowIsolated); joinThreadPool(); &#125; static void instantiate() &#123; publish(); &#125; static status_t shutdown() &#123; return NO_ERROR; &#125;private: static void joinThreadPool() &#123; sp&lt;ProcessState&gt; ps(ProcessState::self()); ps-&gt;startThreadPool(); ps-&gt;giveThreadPoolName(); IPCThreadState::self()-&gt;joinThreadPool(); &#125;&#125;; AudioFlinger（media.audio_flinger）：Audio系统的一个核心服务，是音频策略的执行者，负责输入输出流设备的管理及音频流数据的处理传输。 AudioPolicyService（media.audio_policy）：音频策略的制定者，负责音频设备切换的策略抉择、音量调节策略等。 AAudioService（media.aaudio）：这是Android 8.0加入角色，是OpenSL ES的另外一种选择，需要低延迟的高性能音频应用的另外一种选择。 RadioService（media.radio）：与FM相关的一个服务。 SoundTriggerHwService（media.sound_trigger_hw）：Android语音识别的native服务。]]></content>
      <categories>
        <category>Android Audio</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub搭建个人的博客]]></title>
    <url>%2F2017%2F10%2F30%2FGitHub%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[最近突然间发现，自己过去看过的东西，没过多久就忘得一干二净，每当要用时，又得从头来一遍，真是好记性不如烂笔头，所以有了写笔记的想法，GitHub上可以方便记录自己一切想记录的，于是就在GitHub上开始写笔记，希望自己不要把知识忘得太快。本文记录在Windows环境下使用Hexo搭建GitHub博客的过程。 安装Node.js在nodejs官网下载对应的版本安装下载地址：https://nodejs.org/en/download 安装Git下载地址：https://git-for-windows.github.io 创建GitHub账户进入GitHub主页https://github.com/，依次输入用户名、邮箱、密码，然后点击注册，按默认点击“Finish sign up”。然后进行邮箱验证。 创建GitHub仓库点击“New repository”，新建一个仓库，仓库名为“[yourname].github.io”，这样https://[yourname].github.io 就是你的博客地址了。默认这仓库只有master分支，新建一个hexo分支。 配置Hexo接下来的命令都在Git Bash中执行。 在自己喜欢的位置新建一个blog文件夹，在这个文件夹下打开Git Bash，因为npm是国外服务器，可能执行比较慢，可以使用淘宝镜像，命令如下： $ npm install -g cnpm --registry=https://registry.npm.taobao.org 执行成功后使用淘宝NPM安装Hexo $ cnpm install -g hexo-cli $ cnmp install hexo --save $ hexo -v hexo: 3.4.0 hexo-cli: 1.0.4 os: Windows_NT 6.1.7600 win32 ia32 http_parser: 2.7.0 node: 8.7.0 v8: 6.1.534.42 uv: 1.15.0 zlib: 1.2.11 ares: 1.10.1-DEV modules: 57 nghttp2: 1.25.0 openssl: 1.0.2l icu: 59.1 unicode: 9.0 cldr: 31.0.1 tz: 2017b 到这里hexo已经安装好了 配置ssh keyssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 在C:\Users\yourname\.ssh下会得到密钥id_rsa和id_rsa.pub，用nodepad++打开id_rsa.pub复制全文，打开https://github.com/settings/ssh，Add SSH key，粘贴进去保存。 测试是否配置成功 $ ssh -T git@github.com Hi [yourname]! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 配置git信息$ git config --global user.name &quot;你的用户名&quot; $ git config --global user.email &quot;你的邮箱&quot; 使用Hexo管理博客初始化博客$ hexo init &lt;nodejs-hexo&gt; //初始化nodejs-hexo（文件夹名随意） $ git clone -b hexo https://github.com/[yourname]/[yourname].github.io 将[yourname].github.io文件夹下的.git文件夹拷贝到nodejs-hexo文件夹。 $ cnpm install //安装生成器 $ hexo server //运行（Ctrl + C停止运行） 在浏览器输入localhost:4000，这样就可以在本地看到博客了。 配置博客_config.yml中配置基本信息 title: #博客标题 subtitle: #博客副标题 description: #博客描述 author: #博客作者 language: zh-Hans timezone: Asia/Shanghai _config.yml中配置主题 theme: next _config.yml中配置部署 deploy: type: git repo: https://github.com/[yourname]/[yourname].github.io branch: master 注意：这里的设置冒号后面必须有空格 发布博客$ hexo new &quot;博客名&quot; //增加新文章 $ cnpm install hexo-deployer-git --save //安装hexo git插件 $ git add . $ git commit -m &quot;message&quot; $ git push origin hexo $ hexo generate //生成静态文件 $ hexo deploy //部署 换PC管理博客$ git clone -b hexo https://github.com/[yourname]/[yourname].github.io 在[yourname].github.io中从新安装hexo，就可以写博客及发布博客了。 参考Next主题配置参考：http://theme-next.iissnan.com/theme-settings.html]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
